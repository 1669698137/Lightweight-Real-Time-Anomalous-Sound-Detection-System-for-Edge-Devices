# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eZUluzBURc8zv80H9DV8xIJ6zyps4OkI
"""

# -*- coding: utf-8 -*-
import sounddevice as sd
import numpy as np
import librosa
import pandas as pd
import joblib
import tensorflow as tf
import time
import scipy.stats
import json
import paho.mqtt.client as mqtt
from collections import deque
import psutil

duration = 5
sr = 16000
window_size = 3

# MQTT 閰嶇疆
ONENET_HOST = "mqtts.heclouds.com"
ONENET_PORT = 1883
PRODUCT_ID = "q5HHZKLtNB"
DEVICE_NAME = "device1"
TOKEN = "version=2018-10-31&res=products%2Fq5HHZKLtNB%2Fdevices%2Fdevice1&et=1767196800&method=md5&sign=wL2SW4%2FEw5gghN8zGdZW8w%3D%3D"

client_id = "device1"
username = PRODUCT_ID
password = TOKEN
post_topic = f"$sys/{PRODUCT_ID}/{DEVICE_NAME}/thing/property/post"

def on_publish(client, userdata, mid):
    print(f"[MQTT] Data uploaded, MID={mid}")

mqtt_client = mqtt.Client(client_id=client_id)
mqtt_client.username_pw_set(username, password)
mqtt_client.on_publish = on_publish
mqtt_client.connect(ONENET_HOST, ONENET_PORT, 60)
mqtt_client.loop_start()

scaler = joblib.load("model/scaler.pkl")
interpreter = tf.lite.Interpreter(model_path="model/best_model.tflite")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

def extract_features(signal, sr):
    features = {}
    hop_length = 512
    n_fft = 1024

    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, hop_length=hop_length, n_fft=n_fft)
    mfcc_stats = np.array([
        np.mean(mfcc, axis=1), np.std(mfcc, axis=1),
        scipy.stats.skew(mfcc, axis=1), scipy.stats.kurtosis(mfcc, axis=1)
    ])
    for i in range(13):
        features[f'mfcc_{i}_mean'] = mfcc_stats[0, i]
        features[f'mfcc_{i}_std'] = mfcc_stats[1, i]
        features[f'mfcc_{i}_skew'] = mfcc_stats[2, i]
        features[f'mfcc_{i}_kurt'] = mfcc_stats[3, i]

    stft = librosa.stft(signal, hop_length=hop_length, n_fft=n_fft)
    magnitude = np.abs(stft)

    features['spectral_centroid_mean'] = np.mean(librosa.feature.spectral_centroid(S=magnitude, sr=sr)[0])
    features['spectral_centroid_std'] = np.std(librosa.feature.spectral_centroid(S=magnitude, sr=sr)[0])
    features['spectral_bandwidth_mean'] = np.mean(librosa.feature.spectral_bandwidth(S=magnitude, sr=sr)[0])
    features['spectral_bandwidth_std'] = np.std(librosa.feature.spectral_bandwidth(S=magnitude, sr=sr)[0])
    features['spectral_rolloff_mean'] = np.mean(librosa.feature.spectral_rolloff(S=magnitude, sr=sr)[0])
    features['spectral_rolloff_std'] = np.std(librosa.feature.spectral_rolloff(S=magnitude, sr=sr)[0])

    zcr = librosa.feature.zero_crossing_rate(signal, hop_length=hop_length)[0]
    features['zcr_mean'] = np.mean(zcr)
    features['zcr_std'] = np.std(zcr)

    rms = librosa.feature.rms(y=signal, hop_length=hop_length)[0]
    features['rms_mean'] = np.mean(rms)
    features['rms_std'] = np.std(rms)

    contrast = librosa.feature.spectral_contrast(S=magnitude, sr=sr)
    for i in range(contrast.shape[0]):
        features[f'contrast_{i}_mean'] = np.mean(contrast[i])

    chroma = librosa.feature.chroma_stft(S=magnitude, sr=sr)
    for i in range(12):
        features[f'chroma_{i}_mean'] = np.mean(chroma[i])

    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=32, hop_length=hop_length, n_fft=n_fft)
    mel_spec_db = librosa.power_to_db(mel_spec)
    features['mel_mean'] = np.mean(mel_spec_db)
    features['mel_std'] = np.std(mel_spec_db)
    features['mel_max'] = np.max(mel_spec_db)
    features['mel_min'] = np.min(mel_spec_db)

    for key, value in features.items():
        if np.isnan(value) or np.isinf(value):
            features[key] = 0.0

    return features

print("Starting real-time anomaly detection with sliding window...")
anomaly_window = deque(maxlen=window_size)

while True:
    print(f"\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] Recording...")
    recording = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype='float32')
    sd.wait()

    signal = recording.flatten()
    rms_energy = np.sqrt(np.mean(signal ** 2))
    if rms_energy < 0.0045:
        print(f"Low RMS energy ({rms_energy:.4f}), skipping...")
        time.sleep(1)
        continue

    features = extract_features(signal, sr)
    X = pd.DataFrame([features])
    X_scaled = scaler.transform(X.values).astype(np.float32)

    # 鎺ㄧ悊 + 鎬ц兘璇勪及
    start_time = time.time()
    interpreter.set_tensor(input_details[0]['index'], X_scaled)
    interpreter.invoke()
    prob = interpreter.get_tensor(output_details[0]['index'])[0][0]
    inference_time_ms = round((time.time() - start_time) * 1000, 2)

    cpu_usage = round(psutil.cpu_percent(interval=0.1), 2)
    memory_usage_mb = round(psutil.virtual_memory().used / 1024 / 1024, 2)

    pred = int(prob > 0.9)
    anomaly_window.append(pred)

    status = "Anomaly" if pred == 1 else "Normal"
    print(f"{status} sound (confidence: {prob:.2f})")
    print(f"Inference time: {inference_time_ms} ms")
    print(f"CPU usage: {cpu_usage}%")
    print(f"Memory usage: {memory_usage_mb} MB")

    if len(anomaly_window) == window_size and all(x == 1 for x in anomaly_window):
        print("Confirmed anomaly (3 in a row), uploading to OneNET...")
        msg_id = str(int(time.time() * 1000))
        payload = {
            "id": msg_id,
            "version": "1.0",
            "params": {
                "anomaly": {"value": 1},
                "confidence": {"value": round(float(prob), 3)}
            }
        }
        print(f"[MQTT] Payload: {json.dumps(payload)}")
        mqtt_client.publish(post_topic, json.dumps(payload))
        anomaly_window.clear()

    time.sleep(1)