{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qKQ0VypjkVq",
        "outputId": "b1a95de0-d936-4685-a807-3c49c2bfef33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "os.chdir(path)\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADdNfGzKGhue",
        "outputId": "db727c60-17c7-4db7-e6df-87b6c2c0e3c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing necessary dependency packages...\n",
            "Dependencies installation completed!\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing necessary dependency packages...\")\n",
        "!pip install librosa scikit-learn pandas numpy matplotlib seaborn tqdm imbalanced-learn -q\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import random\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Dependencies installation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    try:\n",
        "        tf.config.experimental.enable_op_determinism()\n",
        "    except AttributeError:\n",
        "        os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "        os.environ['TF_CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "\n",
        "set_seeds(42)"
      ],
      "metadata": {
        "id": "mNHLPPdO2XA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_wAs-xhGib_",
        "outputId": "de280092-ed98-4a4d-9384-43093c695669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Smart Home Threat-Oriented Strategy: 14 anomaly categories\n",
            "   Anomalies: Only real security threats and emergency situations\n",
            "Normal categories: ['dog', 'rooster', 'pig', 'cow', 'frog', 'cat', 'hen', 'insects', 'sheep', 'crow', 'rain', 'sea_waves', 'crickets', 'chirping_birds', 'water_drops', 'wind', 'pouring_water', 'toilet_flush', 'thunderstorm', 'clapping', 'breathing', 'footsteps', 'laughing', 'brushing_teeth', 'snoring', 'drinking_sipping', 'mouse_click', 'keyboard_typing', 'door_wood_creaks', 'can_opening', 'washing_machine', 'vacuum_cleaner', 'clock_alarm', 'clock_tick', 'church_bells', 'fireworks']\n",
            "Expected distribution: 1440 normal, 560 anomaly (28% anomaly)\n",
            "Anomaly categories: ['crackling_fire', 'crying_baby', 'sneezing', 'coughing', 'door_knock', 'glass_breaking', 'helicopter', 'chainsaw', 'siren', 'car_horn', 'engine', 'train', 'airplane', 'hand_saw']\n",
            "Number of anomaly categories: 14\n"
          ]
        }
      ],
      "source": [
        "# Label Strategy\n",
        "DATASET_PATH = \"ESC-50-master\"\n",
        "OUTPUT_DIR = \"processed_data\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "SMART_HOME_CRITICAL_ANOMALIES = [\n",
        "    # Security threats (8)\n",
        "    'glass_breaking', 'siren', 'chainsaw', 'hand_saw',\n",
        "    'helicopter', 'car_horn', 'engine', 'train', 'crackling_fire',\n",
        "\n",
        "    # Intrusion threats (2)\n",
        "    'door_knock', 'airplane',\n",
        "\n",
        "    # Emergency situations (4)\n",
        "    'crying_baby', 'coughing', 'sneezing'\n",
        "]\n",
        "\n",
        "# Define complete ESC-50 category list\n",
        "ALL_ESC50_CATEGORIES = [\n",
        "    # Animal sounds\n",
        "    'dog', 'rooster', 'pig', 'cow', 'frog', 'cat', 'hen', 'insects', 'sheep', 'crow',\n",
        "    # Natural environment\n",
        "    'rain', 'sea_waves', 'crackling_fire', 'crickets', 'chirping_birds',\n",
        "    'water_drops', 'wind', 'pouring_water', 'toilet_flush', 'thunderstorm',\n",
        "    # Human sounds\n",
        "    'crying_baby', 'sneezing', 'clapping', 'breathing', 'coughing',\n",
        "    'footsteps', 'laughing', 'brushing_teeth', 'snoring', 'drinking_sipping',\n",
        "    # Indoor sounds\n",
        "    'door_knock', 'mouse_click', 'keyboard_typing', 'door_wood_creaks',\n",
        "    'can_opening', 'washing_machine', 'vacuum_cleaner', 'clock_alarm',\n",
        "    'clock_tick', 'glass_breaking',\n",
        "    # External sounds\n",
        "    'helicopter', 'chainsaw', 'siren', 'car_horn', 'engine',\n",
        "    'train', 'church_bells', 'airplane', 'fireworks', 'hand_saw'\n",
        "]\n",
        "\n",
        "# Select strategy\n",
        "STRATEGY = \"smart_home_critical\"  # Options: \"smart_home_balanced\", \"smart_home_strict\", \"smart_home_critical\"\n",
        "\n",
        "if STRATEGY == \"smart_home_balanced\":\n",
        "    NORMAL_CATEGORIES = SMART_HOME_NORMAL_CATEGORIES\n",
        "    print(f\"Using Smart Home Balanced Strategy: {len(NORMAL_CATEGORIES)} normal categories\")\n",
        "    print(\"   Includes: Natural environment + Household appliances + Daily life + Pet sounds\")\n",
        "\n",
        "elif STRATEGY == \"smart_home_strict\":\n",
        "    NORMAL_CATEGORIES = SMART_HOME_STRICT_CATEGORIES\n",
        "    print(f\"Using Smart Home Strict Strategy: {len(NORMAL_CATEGORIES)} normal categories\")\n",
        "    print(\"   Includes: Only core household daily sounds\")\n",
        "\n",
        "else:  # smart_home_critical\n",
        "    # Reverse strategy: everything except serious threats is normal\n",
        "    NORMAL_CATEGORIES = [cat for cat in ALL_ESC50_CATEGORIES if cat not in SMART_HOME_CRITICAL_ANOMALIES]\n",
        "    print(f\"Using Smart Home Threat-Oriented Strategy: {len(SMART_HOME_CRITICAL_ANOMALIES)} anomaly categories\")\n",
        "    print(\"   Anomalies: Only real security threats and emergency situations\")\n",
        "\n",
        "print(f\"Normal categories: {NORMAL_CATEGORIES}\")\n",
        "\n",
        "# Expected data distribution\n",
        "if STRATEGY == \"smart_home_balanced\":\n",
        "    expected_normal = len(SMART_HOME_NORMAL_CATEGORIES) * 40  # 40 samples per category\n",
        "    expected_anomaly = (50 - len(SMART_HOME_NORMAL_CATEGORIES)) * 40\n",
        "    print(f\"Expected distribution: {expected_normal} normal, {expected_anomaly} anomaly ({len(SMART_HOME_NORMAL_CATEGORIES)/50*100:.0f}% normal)\")\n",
        "\n",
        "elif STRATEGY == \"smart_home_strict\":\n",
        "    expected_normal = len(SMART_HOME_STRICT_CATEGORIES) * 40\n",
        "    expected_anomaly = (50 - len(SMART_HOME_STRICT_CATEGORIES)) * 40\n",
        "    print(f\"Expected distribution: {expected_normal} normal, {expected_anomaly} anomaly ({len(SMART_HOME_STRICT_CATEGORIES)/50*100:.0f}% normal)\")\n",
        "\n",
        "else:  # smart_home_critical\n",
        "    expected_anomaly = len(SMART_HOME_CRITICAL_ANOMALIES) * 40\n",
        "    expected_normal = (50 - len(SMART_HOME_CRITICAL_ANOMALIES)) * 40\n",
        "    print(f\"Expected distribution: {expected_normal} normal, {expected_anomaly} anomaly ({len(SMART_HOME_CRITICAL_ANOMALIES)/50*100:.0f}% anomaly)\")\n",
        "\n",
        "# Display anomaly categories (applies to all strategies)\n",
        "ANOMALY_CATEGORIES = [cat for cat in ALL_ESC50_CATEGORIES if cat not in NORMAL_CATEGORIES]\n",
        "print(f\"Anomaly categories: {ANOMALY_CATEGORIES}\")\n",
        "print(f\"Number of anomaly categories: {len(ANOMALY_CATEGORIES)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "SnIHYKLAGke9",
        "outputId": "3c696931-1a39-4f6e-fa86-7edc8ffad792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ESC-50 data...\n",
            "Data loading completed:\n",
            "   Total samples: 2000\n",
            "   Normal: 1440 (72.0%)\n",
            "   Anomaly: 560 (28.0%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               filename  fold  target        category  esc10  src_file take  \\\n",
              "0      1-100032-A-0.wav     1       0             dog   True    100032    A   \n",
              "1     1-100038-A-14.wav     1      14  chirping_birds  False    100038    A   \n",
              "2     1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A   \n",
              "3     1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B   \n",
              "4     1-101296-A-19.wav     1      19    thunderstorm  False    101296    A   \n",
              "...                 ...   ...     ...             ...    ...       ...  ...   \n",
              "1995   5-263831-B-6.wav     5       6             hen  False    263831    B   \n",
              "1996  5-263902-A-36.wav     5      36  vacuum_cleaner  False    263902    A   \n",
              "1997   5-51149-A-25.wav     5      25       footsteps  False     51149    A   \n",
              "1998    5-61635-A-8.wav     5       8           sheep  False     61635    A   \n",
              "1999     5-9032-A-0.wav     5       0             dog   True      9032    A   \n",
              "\n",
              "      is_normal  \n",
              "0             1  \n",
              "1             1  \n",
              "2             1  \n",
              "3             1  \n",
              "4             1  \n",
              "...         ...  \n",
              "1995          1  \n",
              "1996          1  \n",
              "1997          1  \n",
              "1998          1  \n",
              "1999          1  \n",
              "\n",
              "[2000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fa85538-3963-44cb-aeba-cc94f1c910fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>fold</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "      <th>esc10</th>\n",
              "      <th>src_file</th>\n",
              "      <th>take</th>\n",
              "      <th>is_normal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-100032-A-0.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>dog</td>\n",
              "      <td>True</td>\n",
              "      <td>100032</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-100038-A-14.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>chirping_birds</td>\n",
              "      <td>False</td>\n",
              "      <td>100038</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-100210-A-36.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>vacuum_cleaner</td>\n",
              "      <td>False</td>\n",
              "      <td>100210</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-100210-B-36.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>vacuum_cleaner</td>\n",
              "      <td>False</td>\n",
              "      <td>100210</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-101296-A-19.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>thunderstorm</td>\n",
              "      <td>False</td>\n",
              "      <td>101296</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>5-263831-B-6.wav</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>hen</td>\n",
              "      <td>False</td>\n",
              "      <td>263831</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>5-263902-A-36.wav</td>\n",
              "      <td>5</td>\n",
              "      <td>36</td>\n",
              "      <td>vacuum_cleaner</td>\n",
              "      <td>False</td>\n",
              "      <td>263902</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>5-51149-A-25.wav</td>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "      <td>footsteps</td>\n",
              "      <td>False</td>\n",
              "      <td>51149</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>5-61635-A-8.wav</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>sheep</td>\n",
              "      <td>False</td>\n",
              "      <td>61635</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>5-9032-A-0.wav</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>dog</td>\n",
              "      <td>True</td>\n",
              "      <td>9032</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fa85538-3963-44cb-aeba-cc94f1c910fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fa85538-3963-44cb-aeba-cc94f1c910fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fa85538-3963-44cb-aeba-cc94f1c910fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-436f88d9-2269-445c-b461-c1403371335f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-436f88d9-2269-445c-b461-c1403371335f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-436f88d9-2269-445c-b461-c1403371335f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_bb99f046-f8f2-4557-bbb5-de4cc323d4db\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('meta_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bb99f046-f8f2-4557-bbb5-de4cc323d4db button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('meta_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "meta_df",
              "summary": "{\n  \"name\": \"meta_df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"5-221950-A-22.wav\",\n          \"1-79220-A-17.wav\",\n          \"4-165845-A-45.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 49,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          45,\n          18,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"train\",\n          \"toilet_flush\",\n          \"laughing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"esc10\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"src_file\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64882,\n        \"min\": 137,\n        \"max\": 264453,\n        \"num_unique_values\": 1524,\n        \"samples\": [\n          155130,\n          21935\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"take\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"B\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_normal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Improved Data Loading\n",
        "def load_esc50_with_labels():\n",
        "    \"\"\"Load ESC-50 data and create smart home anomaly detection labels\"\"\"\n",
        "    print(\"Loading ESC-50 data...\")\n",
        "\n",
        "    # Read metadata\n",
        "    meta_path = os.path.join(DATASET_PATH, 'meta', 'esc50.csv')\n",
        "    meta_df = pd.read_csv(meta_path)\n",
        "\n",
        "    # Create anomaly detection labels - using correct NORMAL_CATEGORIES\n",
        "    meta_df['is_normal'] = meta_df['category'].isin(NORMAL_CATEGORIES).astype(int)\n",
        "\n",
        "    # Basic statistics\n",
        "    normal_count = meta_df['is_normal'].sum()\n",
        "    anomaly_count = len(meta_df) - normal_count\n",
        "\n",
        "    print(f\"Data loading completed:\")\n",
        "    print(f\"   Total samples: {len(meta_df)}\")\n",
        "    print(f\"   Normal: {normal_count} ({normal_count/len(meta_df)*100:.1f}%)\")\n",
        "    print(f\"   Anomaly: {anomaly_count} ({anomaly_count/len(meta_df)*100:.1f}%)\")\n",
        "\n",
        "    return meta_df\n",
        "\n",
        "# Use simplified version\n",
        "meta_df = load_esc50_with_labels()\n",
        "\n",
        "meta_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = meta_df['is_normal'].value_counts()\n",
        "labels = class_counts.index.map({1: 'Normal', 0: 'Anomaly'})\n",
        "sizes = class_counts.values\n",
        "colors = ['#87CEEB', '#FF6347']\n",
        "explode = (0.05, 0)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct=lambda p: '{:.1f}%\\n({:.0f})'.format(p, p * sum(sizes) / 100),\n",
        "        shadow=False, startangle=90, textprops={'fontsize': 12})\n",
        "\n",
        "\n",
        "plt.title('Distribution of Sample Classes', fontsize=16)\n",
        "plt.axis('equal')\n",
        "\n",
        "plt.savefig('figure_5_1_piechart.png', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "Pl_vN64opNho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "fdf4ad0c-da7c-4c7b-a40e-58ab9315f5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOqMbIg3GmpA",
        "outputId": "51f8327f-2aff-4066-be47-57325ef9e9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOTA Feature Extraction + Smart Caching\n",
            "========================================\n",
            "Loaded from cache: (2000, 88)\n",
            "\n",
            "Feature Matrix: (2000, 88)\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# Feature Extraction + Caching\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import scipy.stats\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import multiprocessing as mp\n",
        "import pickle\n",
        "import hashlib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def extract_comprehensive_features_fast(signal, sr):\n",
        "    \"\"\"Fast extraction of audio features\"\"\"\n",
        "    features = {}\n",
        "    hop_length = 512\n",
        "    n_fft = 1024\n",
        "\n",
        "    # 1. MFCC Features\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13,\n",
        "                                hop_length=hop_length, n_fft=n_fft)\n",
        "    mfcc_stats = np.array([\n",
        "        np.mean(mfcc, axis=1), np.std(mfcc, axis=1),\n",
        "        scipy.stats.skew(mfcc, axis=1), scipy.stats.kurtosis(mfcc, axis=1)\n",
        "    ])\n",
        "\n",
        "    for i in range(13):\n",
        "        features[f'mfcc_{i}_mean'] = mfcc_stats[0, i]\n",
        "        features[f'mfcc_{i}_std'] = mfcc_stats[1, i]\n",
        "        features[f'mfcc_{i}_skew'] = mfcc_stats[2, i]\n",
        "        features[f'mfcc_{i}_kurt'] = mfcc_stats[3, i]\n",
        "\n",
        "    # 2. Spectral Features\n",
        "    stft = librosa.stft(signal, hop_length=hop_length, n_fft=n_fft)\n",
        "    magnitude = np.abs(stft)\n",
        "\n",
        "    spectral_centroids = librosa.feature.spectral_centroid(S=magnitude, sr=sr)[0]\n",
        "    features['spectral_centroid_mean'] = np.mean(spectral_centroids)\n",
        "    features['spectral_centroid_std'] = np.std(spectral_centroids)\n",
        "\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(S=magnitude, sr=sr)[0]\n",
        "    features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)\n",
        "    features['spectral_bandwidth_std'] = np.std(spectral_bandwidth)\n",
        "\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(S=magnitude, sr=sr)[0]\n",
        "    features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)\n",
        "    features['spectral_rolloff_std'] = np.std(spectral_rolloff)\n",
        "\n",
        "    # 3. Rhythm & Energy\n",
        "    zcr = librosa.feature.zero_crossing_rate(signal, hop_length=hop_length)[0]\n",
        "    features['zcr_mean'] = np.mean(zcr)\n",
        "    features['zcr_std'] = np.std(zcr)\n",
        "\n",
        "    rms = librosa.feature.rms(y=signal, hop_length=hop_length)[0]\n",
        "    features['rms_mean'] = np.mean(rms)\n",
        "    features['rms_std'] = np.std(rms)\n",
        "\n",
        "    # 4. Spectral Contrast\n",
        "    contrast = librosa.feature.spectral_contrast(S=magnitude, sr=sr, n_bands=6)\n",
        "    for i in range(contrast.shape[0]):\n",
        "        features[f'contrast_{i}_mean'] = np.mean(contrast[i])\n",
        "\n",
        "    # 5. Chroma Features\n",
        "    chroma = librosa.feature.chroma_stft(S=magnitude, sr=sr)\n",
        "    for i in range(12):\n",
        "        features[f'chroma_{i}_mean'] = np.mean(chroma[i])\n",
        "\n",
        "    # 6. Mel Spectrogram\n",
        "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=32,\n",
        "                                              hop_length=hop_length, n_fft=n_fft)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec)\n",
        "    features['mel_mean'] = np.mean(mel_spec_db)\n",
        "    features['mel_std'] = np.std(mel_spec_db)\n",
        "    features['mel_max'] = np.max(mel_spec_db)\n",
        "    features['mel_min'] = np.min(mel_spec_db)\n",
        "\n",
        "    # Handle invalid values\n",
        "    for key, value in features.items():\n",
        "        if np.isnan(value) or np.isinf(value):\n",
        "            features[key] = 0.0\n",
        "\n",
        "    return features\n",
        "\n",
        "def process_single_file(args):\n",
        "    \"\"\"Process a single audio file\"\"\"\n",
        "    file_info, audio_path = args\n",
        "    try:\n",
        "        file_path = audio_path / file_info['filename']\n",
        "        signal, sr = librosa.load(file_path, sr=16000, duration=5.0)\n",
        "\n",
        "        features = extract_comprehensive_features_fast(signal, sr)\n",
        "        features.update({\n",
        "            'filename': file_info['filename'],\n",
        "            'category': file_info['category'],\n",
        "            'is_normal': file_info['is_normal']\n",
        "        })\n",
        "\n",
        "        return features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process: {file_info['filename']} - {e}\")\n",
        "        return None\n",
        "\n",
        "def get_cache_filename(meta_df, sample_size):\n",
        "    \"\"\"Generate cache filename\"\"\"\n",
        "    data_hash = hashlib.md5(str(meta_df.shape).encode()).hexdigest()[:8]\n",
        "    return f\"features_cache_{data_hash}_s{sample_size}.pkl\"\n",
        "\n",
        "def load_from_cache(cache_file):\n",
        "    \"\"\"Load from cache\"\"\"\n",
        "    if Path(cache_file).exists():\n",
        "        try:\n",
        "            with open(cache_file, 'rb') as f:\n",
        "                features_df = pickle.load(f)\n",
        "            print(f\"Loaded from cache: {features_df.shape}\")\n",
        "            return features_df\n",
        "        except:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "def save_to_cache(features_df, cache_file):\n",
        "    \"\"\"Save to cache\"\"\"\n",
        "    try:\n",
        "        with open(cache_file, 'wb') as f:\n",
        "            pickle.dump(features_df, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        print(f\"Saved to cache: {cache_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Cache save failed: {e}\")\n",
        "\n",
        "def quick_load_features(meta_df, sample_size=2000):\n",
        "    \"\"\"Smart feature loader (uses cache if available)\"\"\"\n",
        "\n",
        "    # Check cache\n",
        "    cache_file = get_cache_filename(meta_df, sample_size)\n",
        "    cached_features = load_from_cache(cache_file)\n",
        "    if cached_features is not None:\n",
        "        return cached_features\n",
        "\n",
        "    print(f\"Extracting features ({sample_size} samples)...\")\n",
        "\n",
        "    # Smart sampling\n",
        "    if sample_size < len(meta_df):\n",
        "        normal_samples = meta_df[meta_df['is_normal'] == 1]\n",
        "        abnormal_samples = meta_df[meta_df['is_normal'] == 0]\n",
        "\n",
        "        normal_size = int(sample_size * 0.8)\n",
        "        abnormal_size = sample_size - normal_size\n",
        "\n",
        "        if len(normal_samples) >= normal_size and len(abnormal_samples) >= abnormal_size:\n",
        "            sample_meta = pd.concat([\n",
        "                normal_samples.sample(n=normal_size, random_state=42),\n",
        "                abnormal_samples.sample(n=abnormal_size, random_state=42)\n",
        "            ]).reset_index(drop=True)\n",
        "        else:\n",
        "            sample_meta = meta_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
        "    else:\n",
        "        sample_meta = meta_df.reset_index(drop=True)\n",
        "\n",
        "    print(f\"   Normal: {sum(sample_meta['is_normal'])} | Abnormal: {len(sample_meta) - sum(sample_meta['is_normal'])}\")\n",
        "\n",
        "    # Parallel extraction\n",
        "    audio_path = Path(DATASET_PATH) / 'audio'\n",
        "    file_args = [(row.to_dict(), audio_path) for _, row in sample_meta.iterrows()]\n",
        "    n_workers = max(1, mp.cpu_count() - 1)\n",
        "\n",
        "    features_list = []\n",
        "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
        "        futures = [executor.submit(process_single_file, arg) for arg in file_args]\n",
        "\n",
        "        for future in tqdm(futures, desc=\"Extracting Features\"):\n",
        "            try:\n",
        "                result = future.result(timeout=30)\n",
        "                if result is not None:\n",
        "                    features_list.append(result)\n",
        "            except Exception as e:\n",
        "                print(f\"   Task failed: {e}\")\n",
        "\n",
        "    # Create DataFrame\n",
        "    features_df = pd.DataFrame(features_list)\n",
        "    print(f\"Completed: {len(features_df)} samples\")\n",
        "\n",
        "    # Save to cache\n",
        "    save_to_cache(features_df, cache_file)\n",
        "\n",
        "    return features_df\n",
        "\n",
        "# Main entry\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"SOTA Feature Extraction + Smart Caching\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Load or extract features\n",
        "    features_df = quick_load_features(meta_df, sample_size=2000)\n",
        "\n",
        "    print(f\"\\nFeature Matrix: {features_df.shape}\")\n",
        "    print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G95D6S_QGpdE",
        "outputId": "5c1f7a01-3ff3-4bb9-fa3a-45029daf046e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Fold Cross Validation (k=5) with Comprehensive Metrics...\n",
            "   Feature dimensions: (2000, 85)\n",
            "   Label distribution: Normal=1440, Anomaly=560\n",
            "\n",
            "Fold 1/5:\n",
            "   Results (Anomaly F1): RF=0.527, IF=0.300, OCSVM=0.338, LOF=0.231\n",
            "\n",
            "Fold 2/5:\n",
            "   Results (Anomaly F1): RF=0.522, IF=0.370, OCSVM=0.349, LOF=0.283\n",
            "\n",
            "Fold 3/5:\n",
            "   Results (Anomaly F1): RF=0.462, IF=0.332, OCSVM=0.363, LOF=0.357\n",
            "\n",
            "Fold 4/5:\n",
            "   Results (Anomaly F1): RF=0.580, IF=0.319, OCSVM=0.343, LOF=0.315\n",
            "\n",
            "Fold 5/5:\n",
            "   Results (Anomaly F1): RF=0.416, IF=0.308, OCSVM=0.361, LOF=0.323\n",
            "\n",
            "============================================================\n",
            "K-Fold Final Results (Mean Â± Std Dev):\n",
            "============================================================\n",
            "Model              | Accuracy           | Precision (Anomaly)    | Recall (Anomaly)     | F1-Score (Anomaly)     | AUC (Anomaly)     \n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "RandomForest       | 0.801 Â± 0.014      | 0.835 Â± 0.023          | 0.361 Â± 0.056        | 0.501 Â± 0.057          | 0.870 Â± 0.018     \n",
            "IsolationForest    | 0.622 Â± 0.010      | 0.326 Â± 0.017          | 0.327 Â± 0.036        | 0.326 Â± 0.024          | 0.512 Â± 0.027     \n",
            "OneClassSVM        | 0.619 Â± 0.007      | 0.335 Â± 0.009          | 0.368 Â± 0.013        | 0.351 Â± 0.010          | 0.575 Â± 0.018     \n",
            "LOF                | 0.605 Â± 0.015      | 0.298 Â± 0.033          | 0.307 Â± 0.053        | 0.302 Â± 0.042          | 0.539 Â± 0.028     \n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def test_models_single_fold(X_train, X_val, y_train, y_val):\n",
        "    \"\"\"\n",
        "    Test models on a single fold and return a dictionary of performance metrics.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # --- 1. Random Forest ---\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_val)\n",
        "    y_proba = rf.predict_proba(X_val)[:, 0]  # Probability for anomaly class (label=0)\n",
        "\n",
        "    results['RandomForest'] = {\n",
        "        'accuracy': accuracy_score(y_val, y_pred),\n",
        "        'precision': precision_score(y_val, y_pred, pos_label=0, zero_division=0),\n",
        "        'recall': recall_score(y_val, y_pred, pos_label=0, zero_division=0),\n",
        "        'f1': f1_score(y_val, y_pred, pos_label=0, zero_division=0),\n",
        "        'auc': roc_auc_score((y_val == 0), y_proba)\n",
        "    }\n",
        "\n",
        "    # --- 2. Isolation Forest ---\n",
        "    anomaly_ratio_train = np.mean(y_train == 0)\n",
        "    iso_forest = IsolationForest(contamination=max(0.01, anomaly_ratio_train), random_state=42)\n",
        "    iso_forest.fit(X_train)\n",
        "    iso_pred = iso_forest.predict(X_val)\n",
        "    y_pred_iso = np.where(iso_pred == -1, 0, 1)\n",
        "    y_scores_iso = -iso_forest.score_samples(X_val)\n",
        "\n",
        "    results['IsolationForest'] = {\n",
        "        'accuracy': accuracy_score(y_val, y_pred_iso),\n",
        "        'precision': precision_score(y_val, y_pred_iso, pos_label=0, zero_division=0),\n",
        "        'recall': recall_score(y_val, y_pred_iso, pos_label=0, zero_division=0),\n",
        "        'f1': f1_score(y_val, y_pred_iso, pos_label=0, zero_division=0),\n",
        "        'auc': roc_auc_score((y_val == 0), y_scores_iso)\n",
        "    }\n",
        "\n",
        "    # --- 3. One-Class SVM ---\n",
        "    X_train_normal = X_train[y_train == 1]\n",
        "    oc_svm = OneClassSVM(nu=max(0.01, anomaly_ratio_train), kernel=\"rbf\")\n",
        "    oc_svm.fit(X_train_normal)\n",
        "    svm_pred = oc_svm.predict(X_val)\n",
        "    y_pred_svm = np.where(svm_pred == -1, 0, 1)\n",
        "    y_scores_svm = -oc_svm.decision_function(X_val)\n",
        "\n",
        "    results['OneClassSVM'] = {\n",
        "        'accuracy': accuracy_score(y_val, y_pred_svm),\n",
        "        'precision': precision_score(y_val, y_pred_svm, pos_label=0, zero_division=0),\n",
        "        'recall': recall_score(y_val, y_pred_svm, pos_label=0, zero_division=0),\n",
        "        'f1': f1_score(y_val, y_pred_svm, pos_label=0, zero_division=0),\n",
        "        'auc': roc_auc_score((y_val == 0), y_scores_svm)\n",
        "    }\n",
        "\n",
        "    # --- 4. Local Outlier Factor ---\n",
        "    lof = LocalOutlierFactor(contamination=max(0.01, anomaly_ratio_train), novelty=True)\n",
        "    lof.fit(X_train_normal)\n",
        "    lof_pred = lof.predict(X_val)\n",
        "    y_pred_lof = np.where(lof_pred == -1, 0, 1)\n",
        "    y_scores_lof = -lof.decision_function(X_val)\n",
        "\n",
        "    results['LOF'] = {\n",
        "        'accuracy': accuracy_score(y_val, y_pred_lof),\n",
        "        'precision': precision_score(y_val, y_pred_lof, pos_label=0, zero_division=0),\n",
        "        'recall': recall_score(y_val, y_pred_lof, pos_label=0, zero_division=0),\n",
        "        'f1': f1_score(y_val, y_pred_lof, pos_label=0, zero_division=0),\n",
        "        'auc': roc_auc_score((y_val == 0), y_scores_lof)\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def kfold_validation(features_df, k=5):\n",
        "    \"\"\"\n",
        "    K-Fold Cross Validation with comprehensive metrics for each model.\n",
        "    \"\"\"\n",
        "    print(f\"K-Fold Cross Validation (k={k}) with Comprehensive Metrics...\")\n",
        "\n",
        "    # --- Data Preparation ---\n",
        "    feature_cols = [col for col in features_df.columns if col not in ['filename', 'category', 'is_normal', 'fold']]\n",
        "    X = features_df[feature_cols].values\n",
        "    y = features_df['is_normal'].values\n",
        "    print(f\"   Feature dimensions: {X.shape}\")\n",
        "    print(f\"   Label distribution: Normal={np.sum(y==1)}, Anomaly={np.sum(y==0)}\")\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "    # --- Initialize result storage ---\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "    all_results = {model_name: {metric: [] for metric in metrics}\n",
        "                   for model_name in ['RandomForest', 'IsolationForest', 'OneClassSVM', 'LOF']}\n",
        "\n",
        "    # --- Cross-validation loop ---\n",
        "    for fold_num, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
        "        print(f\"\\nFold {fold_num}/{k}:\")\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        scaler = RobustScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        X_train_scaled = np.nan_to_num(X_train_scaled)\n",
        "        X_val_scaled = np.nan_to_num(X_val_scaled)\n",
        "\n",
        "        fold_results = test_models_single_fold(X_train_scaled, X_val_scaled, y_train, y_val)\n",
        "\n",
        "        for model_name, model_metrics in fold_results.items():\n",
        "            for metric_name, value in model_metrics.items():\n",
        "                all_results[model_name][metric_name].append(value)\n",
        "\n",
        "        # Show fold-wise F1 score (anomaly-focused)\n",
        "        print(f\"   Results (Anomaly F1): RF={fold_results['RandomForest']['f1']:.3f}, IF={fold_results['IsolationForest']['f1']:.3f}, OCSVM={fold_results['OneClassSVM']['f1']:.3f}, LOF={fold_results['LOF']['f1']:.3f}\")\n",
        "\n",
        "    # --- Final aggregated results ---\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"K-Fold Final Results (Mean Â± Std Dev):\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"{'Model':<18} | {'Accuracy':<18} | {'Precision (Anomaly)':<22} | {'Recall (Anomaly)':<20} | {'F1-Score (Anomaly)':<22} | {'AUC (Anomaly)':<18}\")\n",
        "    print(\"-\" * 130)\n",
        "\n",
        "    for model_name, model_metrics in all_results.items():\n",
        "        acc_str = f\"{np.mean(model_metrics['accuracy']):.3f} Â± {np.std(model_metrics['accuracy']):.3f}\"\n",
        "        pre_str = f\"{np.mean(model_metrics['precision']):.3f} Â± {np.std(model_metrics['precision']):.3f}\"\n",
        "        rec_str = f\"{np.mean(model_metrics['recall']):.3f} Â± {np.std(model_metrics['recall']):.3f}\"\n",
        "        f1_str = f\"{np.mean(model_metrics['f1']):.3f} Â± {np.std(model_metrics['f1']):.3f}\"\n",
        "        auc_str = f\"{np.mean(model_metrics['auc']):.3f} Â± {np.std(model_metrics['auc']):.3f}\"\n",
        "\n",
        "        print(f\"{model_name:<18} | {acc_str:<18} | {pre_str:<22} | {rec_str:<20} | {f1_str:<22} | {auc_str:<18}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Run cross-validation\n",
        "kfold_results = kfold_validation(features_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdZGouMuPWx_",
        "outputId": "61fd4a1e-0585-40c9-e6ad-0e1484b49e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "========================================\n",
            "Training set: 1600 samples, Test set: 400 samples\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "Training set: (1600, 85), Anomaly rate: 28.0%\n",
            "Test set: (400, 85), Anomaly rate: 28.0%\n",
            "Data augmentation: 1600 -> 2720 samples\n",
            "Starting training...\n",
            "Epoch 1/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4707 - loss: 1.2436 - val_accuracy: 0.8787 - val_loss: 0.4161 - learning_rate: 5.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5305 - loss: 1.0240 - val_accuracy: 0.8879 - val_loss: 0.4138 - learning_rate: 5.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5557 - loss: 0.9833 - val_accuracy: 0.8842 - val_loss: 0.3971 - learning_rate: 5.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5858 - loss: 0.9177 - val_accuracy: 0.8934 - val_loss: 0.3859 - learning_rate: 5.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5965 - loss: 0.9043 - val_accuracy: 0.8989 - val_loss: 0.3800 - learning_rate: 5.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6239 - loss: 0.8637 - val_accuracy: 0.9154 - val_loss: 0.3610 - learning_rate: 5.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6310 - loss: 0.8597 - val_accuracy: 0.9118 - val_loss: 0.3614 - learning_rate: 5.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6460 - loss: 0.8518 - val_accuracy: 0.9154 - val_loss: 0.3508 - learning_rate: 5.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6379 - loss: 0.8225 - val_accuracy: 0.9154 - val_loss: 0.3387 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6401 - loss: 0.8210 - val_accuracy: 0.9191 - val_loss: 0.3461 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6674 - loss: 0.8208 - val_accuracy: 0.9283 - val_loss: 0.3328 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6724 - loss: 0.7750 - val_accuracy: 0.9265 - val_loss: 0.3268 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6832 - loss: 0.7549 - val_accuracy: 0.9191 - val_loss: 0.3188 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6898 - loss: 0.7419 - val_accuracy: 0.9173 - val_loss: 0.3189 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6924 - loss: 0.7528 - val_accuracy: 0.9081 - val_loss: 0.3158 - learning_rate: 5.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7154 - loss: 0.7142 - val_accuracy: 0.9081 - val_loss: 0.3100 - learning_rate: 5.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7022 - loss: 0.7276 - val_accuracy: 0.9154 - val_loss: 0.3019 - learning_rate: 5.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7217 - loss: 0.6929 - val_accuracy: 0.9173 - val_loss: 0.3020 - learning_rate: 5.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.6861 - val_accuracy: 0.9154 - val_loss: 0.2951 - learning_rate: 5.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.6633 - val_accuracy: 0.9136 - val_loss: 0.2843 - learning_rate: 5.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.6714 - val_accuracy: 0.9154 - val_loss: 0.2831 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7358 - loss: 0.6742 - val_accuracy: 0.9173 - val_loss: 0.2781 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7314 - loss: 0.6840 - val_accuracy: 0.9301 - val_loss: 0.2703 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7355 - loss: 0.6545 - val_accuracy: 0.9283 - val_loss: 0.2767 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.6517 - val_accuracy: 0.9283 - val_loss: 0.2707 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7492 - loss: 0.6434 - val_accuracy: 0.9246 - val_loss: 0.2627 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.6151 - val_accuracy: 0.9228 - val_loss: 0.2649 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.6418 - val_accuracy: 0.9246 - val_loss: 0.2634 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7446 - loss: 0.6412 - val_accuracy: 0.9228 - val_loss: 0.2708 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.6038 - val_accuracy: 0.9246 - val_loss: 0.2558 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.5863 - val_accuracy: 0.9246 - val_loss: 0.2579 - learning_rate: 5.0000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7613 - loss: 0.6022 - val_accuracy: 0.9228 - val_loss: 0.2576 - learning_rate: 5.0000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7788 - loss: 0.5727 - val_accuracy: 0.9338 - val_loss: 0.2431 - learning_rate: 5.0000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7681 - loss: 0.5942 - val_accuracy: 0.9393 - val_loss: 0.2513 - learning_rate: 5.0000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7892 - loss: 0.5742 - val_accuracy: 0.9338 - val_loss: 0.2436 - learning_rate: 5.0000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.5574 - val_accuracy: 0.9338 - val_loss: 0.2421 - learning_rate: 5.0000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.5652 - val_accuracy: 0.9412 - val_loss: 0.2297 - learning_rate: 5.0000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7718 - loss: 0.5904 - val_accuracy: 0.9449 - val_loss: 0.2373 - learning_rate: 5.0000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.5578 - val_accuracy: 0.9467 - val_loss: 0.2238 - learning_rate: 5.0000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7968 - loss: 0.5605 - val_accuracy: 0.9467 - val_loss: 0.2198 - learning_rate: 5.0000e-04\n",
            "Epoch 41/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.5748 - val_accuracy: 0.9393 - val_loss: 0.2214 - learning_rate: 5.0000e-04\n",
            "Epoch 42/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7930 - loss: 0.5345 - val_accuracy: 0.9485 - val_loss: 0.2194 - learning_rate: 5.0000e-04\n",
            "Epoch 43/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.5138 - val_accuracy: 0.9393 - val_loss: 0.2103 - learning_rate: 5.0000e-04\n",
            "Epoch 44/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.5187 - val_accuracy: 0.9449 - val_loss: 0.2162 - learning_rate: 5.0000e-04\n",
            "Epoch 45/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.5331 - val_accuracy: 0.9504 - val_loss: 0.2019 - learning_rate: 5.0000e-04\n",
            "Epoch 46/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.5195 - val_accuracy: 0.9540 - val_loss: 0.2023 - learning_rate: 5.0000e-04\n",
            "Epoch 47/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.4879 - val_accuracy: 0.9522 - val_loss: 0.2055 - learning_rate: 5.0000e-04\n",
            "Epoch 48/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.5664 - val_accuracy: 0.9540 - val_loss: 0.2082 - learning_rate: 5.0000e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.5162 - val_accuracy: 0.9614 - val_loss: 0.1919 - learning_rate: 5.0000e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.4813 - val_accuracy: 0.9540 - val_loss: 0.1984 - learning_rate: 5.0000e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.5138 - val_accuracy: 0.9522 - val_loss: 0.1969 - learning_rate: 5.0000e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.4810 - val_accuracy: 0.9504 - val_loss: 0.1941 - learning_rate: 5.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.5043 - val_accuracy: 0.9559 - val_loss: 0.1894 - learning_rate: 5.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.4726 - val_accuracy: 0.9522 - val_loss: 0.1973 - learning_rate: 5.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.4619 - val_accuracy: 0.9577 - val_loss: 0.1856 - learning_rate: 5.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 0.4734 - val_accuracy: 0.9632 - val_loss: 0.1814 - learning_rate: 5.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8268 - loss: 0.4985 - val_accuracy: 0.9614 - val_loss: 0.1787 - learning_rate: 5.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.4546 - val_accuracy: 0.9540 - val_loss: 0.1933 - learning_rate: 5.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8291 - loss: 0.4716 - val_accuracy: 0.9651 - val_loss: 0.1730 - learning_rate: 5.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8460 - loss: 0.4590 - val_accuracy: 0.9504 - val_loss: 0.1886 - learning_rate: 5.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8552 - loss: 0.4183 - val_accuracy: 0.9632 - val_loss: 0.1717 - learning_rate: 5.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8490 - loss: 0.4278 - val_accuracy: 0.9632 - val_loss: 0.1654 - learning_rate: 5.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8352 - loss: 0.4546 - val_accuracy: 0.9577 - val_loss: 0.1644 - learning_rate: 5.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.4300 - val_accuracy: 0.9596 - val_loss: 0.1678 - learning_rate: 5.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.4352 - val_accuracy: 0.9614 - val_loss: 0.1649 - learning_rate: 5.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.4295 - val_accuracy: 0.9614 - val_loss: 0.1621 - learning_rate: 5.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8662 - loss: 0.4045 - val_accuracy: 0.9614 - val_loss: 0.1600 - learning_rate: 5.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.4074 - val_accuracy: 0.9596 - val_loss: 0.1482 - learning_rate: 5.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.4256 - val_accuracy: 0.9669 - val_loss: 0.1479 - learning_rate: 5.0000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8575 - loss: 0.4232 - val_accuracy: 0.9632 - val_loss: 0.1520 - learning_rate: 5.0000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.4029 - val_accuracy: 0.9651 - val_loss: 0.1420 - learning_rate: 5.0000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.4167 - val_accuracy: 0.9614 - val_loss: 0.1565 - learning_rate: 5.0000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.4013 - val_accuracy: 0.9651 - val_loss: 0.1419 - learning_rate: 5.0000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8698 - loss: 0.3829 - val_accuracy: 0.9559 - val_loss: 0.1546 - learning_rate: 5.0000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.3814 - val_accuracy: 0.9651 - val_loss: 0.1399 - learning_rate: 5.0000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8651 - loss: 0.3939 - val_accuracy: 0.9596 - val_loss: 0.1545 - learning_rate: 5.0000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8802 - loss: 0.3775 - val_accuracy: 0.9651 - val_loss: 0.1414 - learning_rate: 5.0000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.3880 - val_accuracy: 0.9651 - val_loss: 0.1324 - learning_rate: 5.0000e-04\n",
            "Epoch 79/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8751 - loss: 0.3643 - val_accuracy: 0.9706 - val_loss: 0.1323 - learning_rate: 5.0000e-04\n",
            "Epoch 80/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8829 - loss: 0.3534 - val_accuracy: 0.9669 - val_loss: 0.1303 - learning_rate: 5.0000e-04\n",
            "Epoch 81/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.3761 - val_accuracy: 0.9614 - val_loss: 0.1308 - learning_rate: 5.0000e-04\n",
            "Epoch 82/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8756 - loss: 0.3673 - val_accuracy: 0.9632 - val_loss: 0.1246 - learning_rate: 5.0000e-04\n",
            "Epoch 83/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.3564 - val_accuracy: 0.9632 - val_loss: 0.1270 - learning_rate: 5.0000e-04\n",
            "Epoch 84/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.3794 - val_accuracy: 0.9816 - val_loss: 0.1187 - learning_rate: 5.0000e-04\n",
            "Epoch 85/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8790 - loss: 0.3752 - val_accuracy: 0.9688 - val_loss: 0.1196 - learning_rate: 5.0000e-04\n",
            "Epoch 86/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8889 - loss: 0.3445 - val_accuracy: 0.9669 - val_loss: 0.1239 - learning_rate: 5.0000e-04\n",
            "Epoch 87/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8816 - loss: 0.3687 - val_accuracy: 0.9688 - val_loss: 0.1211 - learning_rate: 5.0000e-04\n",
            "Epoch 88/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8833 - loss: 0.3445 - val_accuracy: 0.9743 - val_loss: 0.1089 - learning_rate: 5.0000e-04\n",
            "Epoch 89/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8768 - loss: 0.3467 - val_accuracy: 0.9743 - val_loss: 0.1173 - learning_rate: 5.0000e-04\n",
            "Epoch 90/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8863 - loss: 0.3494 - val_accuracy: 0.9706 - val_loss: 0.1130 - learning_rate: 5.0000e-04\n",
            "Epoch 91/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8826 - loss: 0.3526 - val_accuracy: 0.9798 - val_loss: 0.1054 - learning_rate: 5.0000e-04\n",
            "Epoch 92/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.3563 - val_accuracy: 0.9743 - val_loss: 0.1054 - learning_rate: 5.0000e-04\n",
            "Epoch 93/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8993 - loss: 0.3119 - val_accuracy: 0.9688 - val_loss: 0.1119 - learning_rate: 5.0000e-04\n",
            "Epoch 94/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.3170 - val_accuracy: 0.9761 - val_loss: 0.1068 - learning_rate: 5.0000e-04\n",
            "Epoch 95/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.3576 - val_accuracy: 0.9724 - val_loss: 0.1097 - learning_rate: 5.0000e-04\n",
            "Epoch 96/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.3028 - val_accuracy: 0.9761 - val_loss: 0.1051 - learning_rate: 5.0000e-04\n",
            "Epoch 97/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8993 - loss: 0.3208 - val_accuracy: 0.9816 - val_loss: 0.0959 - learning_rate: 5.0000e-04\n",
            "Epoch 98/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.3351 - val_accuracy: 0.9761 - val_loss: 0.0989 - learning_rate: 5.0000e-04\n",
            "Epoch 99/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.3043 - val_accuracy: 0.9761 - val_loss: 0.0977 - learning_rate: 5.0000e-04\n",
            "Epoch 100/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.3016 - val_accuracy: 0.9743 - val_loss: 0.1000 - learning_rate: 5.0000e-04\n",
            "Epoch 101/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.3028 - val_accuracy: 0.9761 - val_loss: 0.0957 - learning_rate: 5.0000e-04\n",
            "Epoch 102/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8985 - loss: 0.3133 - val_accuracy: 0.9669 - val_loss: 0.1055 - learning_rate: 5.0000e-04\n",
            "Epoch 103/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9071 - loss: 0.2782 - val_accuracy: 0.9761 - val_loss: 0.0939 - learning_rate: 5.0000e-04\n",
            "Epoch 104/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.3396 - val_accuracy: 0.9724 - val_loss: 0.1026 - learning_rate: 5.0000e-04\n",
            "Epoch 105/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.3048 - val_accuracy: 0.9835 - val_loss: 0.0896 - learning_rate: 5.0000e-04\n",
            "Epoch 106/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2586 - val_accuracy: 0.9853 - val_loss: 0.0916 - learning_rate: 5.0000e-04\n",
            "Epoch 107/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.2983 - val_accuracy: 0.9853 - val_loss: 0.0841 - learning_rate: 5.0000e-04\n",
            "Epoch 108/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8915 - loss: 0.2896 - val_accuracy: 0.9779 - val_loss: 0.0828 - learning_rate: 5.0000e-04\n",
            "Epoch 109/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.2822 - val_accuracy: 0.9743 - val_loss: 0.0884 - learning_rate: 5.0000e-04\n",
            "Epoch 110/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9081 - loss: 0.2745 - val_accuracy: 0.9724 - val_loss: 0.0900 - learning_rate: 5.0000e-04\n",
            "Epoch 111/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9004 - loss: 0.3007 - val_accuracy: 0.9706 - val_loss: 0.0882 - learning_rate: 5.0000e-04\n",
            "Epoch 112/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9054 - loss: 0.2847 - val_accuracy: 0.9779 - val_loss: 0.0866 - learning_rate: 5.0000e-04\n",
            "Epoch 113/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9239 - loss: 0.2649 - val_accuracy: 0.9853 - val_loss: 0.0748 - learning_rate: 5.0000e-04\n",
            "Epoch 114/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2589 - val_accuracy: 0.9871 - val_loss: 0.0818 - learning_rate: 5.0000e-04\n",
            "Epoch 115/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2829 - val_accuracy: 0.9853 - val_loss: 0.0772 - learning_rate: 5.0000e-04\n",
            "Epoch 116/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.2960 - val_accuracy: 0.9908 - val_loss: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 117/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9090 - loss: 0.2729 - val_accuracy: 0.9853 - val_loss: 0.0807 - learning_rate: 5.0000e-04\n",
            "Epoch 118/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9042 - loss: 0.2948 - val_accuracy: 0.9835 - val_loss: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 119/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2619 - val_accuracy: 0.9908 - val_loss: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 120/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9131 - loss: 0.2537 - val_accuracy: 0.9926 - val_loss: 0.0773 - learning_rate: 5.0000e-04\n",
            "Epoch 121/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2489 - val_accuracy: 0.9963 - val_loss: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 122/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9160 - loss: 0.2498 - val_accuracy: 0.9908 - val_loss: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 123/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2679 - val_accuracy: 0.9945 - val_loss: 0.0738 - learning_rate: 5.0000e-04\n",
            "Epoch 124/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.2742 - val_accuracy: 0.9963 - val_loss: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 125/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.2503 - val_accuracy: 0.9926 - val_loss: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 126/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9279 - loss: 0.2292 - val_accuracy: 0.9908 - val_loss: 0.0692 - learning_rate: 5.0000e-04\n",
            "Epoch 127/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.2536 - val_accuracy: 0.9945 - val_loss: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 128/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2509 - val_accuracy: 0.9926 - val_loss: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 129/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2499 - val_accuracy: 0.9890 - val_loss: 0.0711 - learning_rate: 5.0000e-04\n",
            "Epoch 130/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9310 - loss: 0.2412 - val_accuracy: 0.9945 - val_loss: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 131/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.2453 - val_accuracy: 0.9945 - val_loss: 0.0597 - learning_rate: 5.0000e-04\n",
            "Epoch 132/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9288 - loss: 0.2376 - val_accuracy: 0.9926 - val_loss: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 133/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9036 - loss: 0.2704 - val_accuracy: 0.9926 - val_loss: 0.0559 - learning_rate: 5.0000e-04\n",
            "Epoch 134/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.2700 - val_accuracy: 0.9926 - val_loss: 0.0665 - learning_rate: 5.0000e-04\n",
            "Epoch 135/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9188 - loss: 0.2628 - val_accuracy: 0.9945 - val_loss: 0.0565 - learning_rate: 5.0000e-04\n",
            "Epoch 136/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9194 - loss: 0.2584 - val_accuracy: 0.9926 - val_loss: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 137/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.2400 - val_accuracy: 0.9963 - val_loss: 0.0589 - learning_rate: 5.0000e-04\n",
            "Epoch 138/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.2516 - val_accuracy: 0.9982 - val_loss: 0.0547 - learning_rate: 5.0000e-04\n",
            "Epoch 139/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9318 - loss: 0.2217 - val_accuracy: 0.9982 - val_loss: 0.0503 - learning_rate: 5.0000e-04\n",
            "Epoch 140/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2079 - val_accuracy: 0.9945 - val_loss: 0.0501 - learning_rate: 5.0000e-04\n",
            "Epoch 141/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9068 - loss: 0.2767 - val_accuracy: 0.9963 - val_loss: 0.0504 - learning_rate: 5.0000e-04\n",
            "Epoch 142/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.2366 - val_accuracy: 0.9945 - val_loss: 0.0534 - learning_rate: 5.0000e-04\n",
            "Epoch 143/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.2192 - val_accuracy: 0.9926 - val_loss: 0.0560 - learning_rate: 5.0000e-04\n",
            "Epoch 144/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.2366 - val_accuracy: 0.9945 - val_loss: 0.0506 - learning_rate: 5.0000e-04\n",
            "Epoch 145/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1898 - val_accuracy: 0.9945 - val_loss: 0.0450 - learning_rate: 5.0000e-04\n",
            "Epoch 146/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9383 - loss: 0.1935 - val_accuracy: 0.9945 - val_loss: 0.0520 - learning_rate: 5.0000e-04\n",
            "Epoch 147/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9361 - loss: 0.1979 - val_accuracy: 0.9945 - val_loss: 0.0468 - learning_rate: 5.0000e-04\n",
            "Epoch 148/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.2110 - val_accuracy: 0.9908 - val_loss: 0.0552 - learning_rate: 5.0000e-04\n",
            "Epoch 149/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9342 - loss: 0.2027 - val_accuracy: 0.9963 - val_loss: 0.0480 - learning_rate: 5.0000e-04\n",
            "Epoch 150/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9329 - loss: 0.2043 - val_accuracy: 0.9982 - val_loss: 0.0443 - learning_rate: 5.0000e-04\n",
            "Epoch 151/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9389 - loss: 0.2128 - val_accuracy: 0.9982 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
            "Epoch 152/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.2054 - val_accuracy: 0.9982 - val_loss: 0.0442 - learning_rate: 5.0000e-04\n",
            "Epoch 153/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9300 - loss: 0.1990 - val_accuracy: 0.9982 - val_loss: 0.0456 - learning_rate: 5.0000e-04\n",
            "Epoch 154/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9387 - loss: 0.2025 - val_accuracy: 0.9982 - val_loss: 0.0398 - learning_rate: 5.0000e-04\n",
            "Epoch 155/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.2079 - val_accuracy: 0.9982 - val_loss: 0.0444 - learning_rate: 5.0000e-04\n",
            "Epoch 156/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9232 - loss: 0.2163 - val_accuracy: 0.9963 - val_loss: 0.0464 - learning_rate: 5.0000e-04\n",
            "Epoch 157/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9472 - loss: 0.1735 - val_accuracy: 0.9963 - val_loss: 0.0476 - learning_rate: 5.0000e-04\n",
            "Epoch 158/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.1908 - val_accuracy: 0.9963 - val_loss: 0.0482 - learning_rate: 5.0000e-04\n",
            "Epoch 159/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1918 - val_accuracy: 0.9982 - val_loss: 0.0411 - learning_rate: 5.0000e-04\n",
            "Epoch 160/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.2053 - val_accuracy: 0.9982 - val_loss: 0.0442 - learning_rate: 5.0000e-04\n",
            "Epoch 161/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.1746 - val_accuracy: 0.9982 - val_loss: 0.0427 - learning_rate: 1.5000e-04\n",
            "Epoch 162/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.1963 - val_accuracy: 0.9982 - val_loss: 0.0422 - learning_rate: 1.5000e-04\n",
            "Epoch 163/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.2148 - val_accuracy: 0.9982 - val_loss: 0.0415 - learning_rate: 1.5000e-04\n",
            "Epoch 164/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1756 - val_accuracy: 0.9982 - val_loss: 0.0420 - learning_rate: 1.5000e-04\n",
            "Epoch 165/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.1735 - val_accuracy: 0.9982 - val_loss: 0.0409 - learning_rate: 1.5000e-04\n",
            "Epoch 166/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9446 - loss: 0.1783 - val_accuracy: 0.9982 - val_loss: 0.0426 - learning_rate: 1.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Information:\n",
            "  Structure: 56â†’28â†’1, Parameters: 6,441, Size: 25.2KB\n",
            "  Training epochs: 166\n",
            "\n",
            "Test Results:\n",
            "  Accuracy: 0.838, AUC: 0.904\n",
            "\n",
            "Normal Class (Label=1):\n",
            "  Precision: 0.911\n",
            "  Recall: 0.858\n",
            "  F1: 0.884\n",
            "\n",
            "Anomaly Class (Label=0):\n",
            "  Precision: 0.682\n",
            "  Recall: 0.786\n",
            "  F1: 0.730\n",
            "\n",
            "Summary:\n",
            "  Structure: 56â†’28â†’1\n",
            "  Parameters: 6,441\n",
            "  Size: 25.2KB\n",
            "  Overall F1: 0.807\n",
            "  Normal Class F1: 0.884\n",
            "  Anomaly Class F1: 0.730\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def smart_data_augmentation(X, y, factor=3.0):\n",
        "    \"\"\"Enhanced data augmentation\"\"\"\n",
        "    minority_idx = np.where(y == 0)[0]\n",
        "    if len(minority_idx) == 0:\n",
        "        return X, y\n",
        "\n",
        "    n_augment = min(int(factor * len(minority_idx)), len(X))\n",
        "    aug_idx = np.random.choice(minority_idx, n_augment, replace=True)\n",
        "\n",
        "    # Multiple augmentation strategies\n",
        "    X_aug_list = []\n",
        "    for i, idx in enumerate(aug_idx):\n",
        "        if i % 3 == 0:\n",
        "            # Gaussian noise\n",
        "            aug_sample = X[idx] + np.random.normal(0, 0.01, X.shape[1])\n",
        "        elif i % 3 == 1:\n",
        "            # Feature perturbation\n",
        "            aug_sample = X[idx].copy()\n",
        "            mask = np.random.random(X.shape[1]) < 0.15\n",
        "            aug_sample[mask] *= np.random.uniform(0.85, 1.15, np.sum(mask))\n",
        "        else:\n",
        "            # Mixed strategy\n",
        "            aug_sample = X[idx] + np.random.normal(0, 0.005, X.shape[1])\n",
        "            mask = np.random.random(X.shape[1]) < 0.1\n",
        "            aug_sample[mask] *= np.random.uniform(0.9, 1.1, np.sum(mask))\n",
        "\n",
        "        X_aug_list.append(aug_sample)\n",
        "\n",
        "    X_aug = np.array(X_aug_list)\n",
        "    y_aug = y[aug_idx]\n",
        "\n",
        "    return np.vstack([X, X_aug]), np.hstack([y, y_aug])\n",
        "\n",
        "def build_lightweight_model(input_dim):\n",
        "    \"\"\"Build optimized lightweight model (56â†’28â†’1)\"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(56, activation='relu', input_shape=(input_dim,), kernel_initializer='he_normal'),\n",
        "        layers.Dropout(0.35),\n",
        "        layers.Dense(28, activation='relu', kernel_initializer='he_normal'),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_lightweight_model(train_features_df, test_features_df, epochs=40, verbose=True):\n",
        "    \"\"\"Train optimized lightweight model\"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Optimized Lightweight Model Training (56â†’28â†’1)\")\n",
        "\n",
        "    # Prepare data\n",
        "    feature_cols = [col for col in train_features_df.columns\n",
        "                   if col not in ['filename', 'category', 'is_normal', 'fold']]\n",
        "\n",
        "    X_train = train_features_df[feature_cols].values\n",
        "    y_train = train_features_df['is_normal'].values\n",
        "    X_test = test_features_df[feature_cols].values\n",
        "    y_test = test_features_df['is_normal'].values\n",
        "\n",
        "    # Data standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_train_scaled = np.nan_to_num(X_train_scaled, 0)\n",
        "    X_test_scaled = np.nan_to_num(X_test_scaled, 0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Training set: {X_train.shape}, Anomaly rate: {(1-np.mean(y_train))*100:.1f}%\")\n",
        "        print(f\"Test set: {X_test.shape}, Anomaly rate: {(1-np.mean(y_test))*100:.1f}%\")\n",
        "\n",
        "    # Enhanced data augmentation\n",
        "    X_train_aug, y_train_aug = smart_data_augmentation(X_train_scaled, y_train, factor=2.5)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Data augmentation: {len(X_train_scaled)} -> {len(X_train_aug)} samples\")\n",
        "\n",
        "    # Build and compile model\n",
        "    model = build_lightweight_model(X_train_scaled.shape[1])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Optimized callbacks\n",
        "    callbacks_list = [\n",
        "        callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=0),\n",
        "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=6, min_lr=1e-7, verbose=0)\n",
        "    ]\n",
        "\n",
        "    # Class weights - focus on anomaly detection optimization\n",
        "    class_weight = {\n",
        "        0: 2.0,  # Increased weight for anomaly class\n",
        "        1: 1.0   # Normal class weight\n",
        "    }\n",
        "\n",
        "    # Train model\n",
        "    if verbose:\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_aug, y_train_aug,\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        class_weight=class_weight,  # Add class weights\n",
        "        callbacks=callbacks_list,\n",
        "        verbose=1 if verbose else 0\n",
        "    )\n",
        "\n",
        "    # Test set evaluation\n",
        "    test_probs = model.predict(X_test_scaled, verbose=0).flatten()\n",
        "    test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "    # Overall metrics\n",
        "    test_metrics = {\n",
        "        'accuracy': accuracy_score(y_test, test_preds),\n",
        "        'auc': roc_auc_score(y_test, test_probs)\n",
        "    }\n",
        "\n",
        "    # Normal class metrics (label=1)\n",
        "    normal_metrics = {\n",
        "        'precision': precision_score(y_test, test_preds, pos_label=1, zero_division=0),\n",
        "        'recall': recall_score(y_test, test_preds, pos_label=1, zero_division=0),\n",
        "        'f1': f1_score(y_test, test_preds, pos_label=1, zero_division=0)\n",
        "    }\n",
        "\n",
        "    # Anomaly class metrics (label=0)\n",
        "    anomaly_metrics = {\n",
        "        'precision': precision_score(y_test, test_preds, pos_label=0, zero_division=0),\n",
        "        'recall': recall_score(y_test, test_preds, pos_label=0, zero_division=0),\n",
        "        'f1': f1_score(y_test, test_preds, pos_label=0, zero_division=0)\n",
        "    }\n",
        "\n",
        "    # Model information\n",
        "    total_params = model.count_params()\n",
        "    model_size_kb = total_params * 4 / 1024\n",
        "\n",
        "\n",
        "    model.save('best_model.h5')\n",
        "    model.save('best_model.keras')\n",
        "\n",
        "    joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nModel Information:\")\n",
        "        print(f\"  Structure: 56â†’28â†’1, Parameters: {total_params:,}, Size: {model_size_kb:.1f}KB\")\n",
        "        print(f\"  Training epochs: {len(history.history['loss'])}\")\n",
        "\n",
        "        print(f\"\\nTest Results:\")\n",
        "        print(f\"  Accuracy: {test_metrics['accuracy']:.3f}, AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        print(f\"\\nNormal Class (Label=1):\")\n",
        "        print(f\"  Precision: {normal_metrics['precision']:.3f}\")\n",
        "        print(f\"  Recall: {normal_metrics['recall']:.3f}\")\n",
        "        print(f\"  F1: {normal_metrics['f1']:.3f}\")\n",
        "\n",
        "        print(f\"\\nAnomaly Class (Label=0):\")\n",
        "        print(f\"  Precision: {anomaly_metrics['precision']:.3f}\")\n",
        "        print(f\"  Recall: {anomaly_metrics['recall']:.3f}\")\n",
        "        print(f\"  F1: {anomaly_metrics['f1']:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'scaler': scaler,\n",
        "        'history': history.history,\n",
        "        'test_metrics': test_metrics,\n",
        "        'normal_metrics': normal_metrics,\n",
        "        'anomaly_metrics': anomaly_metrics,\n",
        "        'feature_columns': feature_cols,\n",
        "        'model_info': {\n",
        "            'structure': '56â†’28â†’1',\n",
        "            'total_params': total_params,\n",
        "            'size_kb': model_size_kb,\n",
        "            'hardware_friendly': True,\n",
        "            'optimizations': ['Class weight 2.0x', 'Enhanced data augmentation 3.0x', 'Learning rate optimization']\n",
        "        }\n",
        "    }\n",
        "\n",
        "def run_lightweight_training(features_df, test_size=0.2, epochs=40):\n",
        "    \"\"\"Run optimized lightweight model training\"\"\"\n",
        "\n",
        "    print(\"Optimized Lightweight Model Training (56â†’28â†’1)\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Split data\n",
        "    train_features_df, test_features_df = train_test_split(\n",
        "        features_df,\n",
        "        test_size=test_size,\n",
        "        stratify=features_df['is_normal'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(train_features_df)} samples, Test set: {len(test_features_df)} samples\")\n",
        "\n",
        "    # Train model\n",
        "    result = train_lightweight_model(\n",
        "        train_features_df, test_features_df,\n",
        "        epochs=epochs, verbose=True\n",
        "    )\n",
        "\n",
        "    # Summary\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"  Structure: {result['model_info']['structure']}\")\n",
        "    print(f\"  Parameters: {result['model_info']['total_params']:,}\")\n",
        "    print(f\"  Size: {result['model_info']['size_kb']:.1f}KB\")\n",
        "    print(f\"  Overall F1: {(result['normal_metrics']['f1'] + result['anomaly_metrics']['f1'])/2:.3f}\")\n",
        "    print(f\"  Normal Class F1: {result['normal_metrics']['f1']:.3f}\")\n",
        "    print(f\"  Anomaly Class F1: {result['anomaly_metrics']['f1']:.3f}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "result = run_lightweight_training(features_df, test_size=0.2, epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGCEldtwkUKJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def smart_data_augmentation(X, y, factor=3.0):\n",
        "    \"\"\"Enhanced data augmentation\"\"\"\n",
        "    minority_idx = np.where(y == 0)[0]\n",
        "    if len(minority_idx) == 0:\n",
        "        return X, y\n",
        "\n",
        "    n_augment = min(int(factor * len(minority_idx)), len(X))\n",
        "    aug_idx = np.random.choice(minority_idx, n_augment, replace=True)\n",
        "\n",
        "    # Multiple augmentation strategies\n",
        "    X_aug_list = []\n",
        "    for i, idx in enumerate(aug_idx):\n",
        "        if i % 3 == 0:\n",
        "            # Gaussian noise\n",
        "            aug_sample = X[idx] + np.random.normal(0, 0.01, X.shape[1])\n",
        "        elif i % 3 == 1:\n",
        "            # Feature perturbation\n",
        "            aug_sample = X[idx].copy()\n",
        "            mask = np.random.random(X.shape[1]) < 0.15\n",
        "            aug_sample[mask] *= np.random.uniform(0.85, 1.15, np.sum(mask))\n",
        "        else:\n",
        "            # Mixed strategy\n",
        "            aug_sample = X[idx] + np.random.normal(0, 0.005, X.shape[1])\n",
        "            mask = np.random.random(X.shape[1]) < 0.1\n",
        "            aug_sample[mask] *= np.random.uniform(0.9, 1.1, np.sum(mask))\n",
        "\n",
        "        X_aug_list.append(aug_sample)\n",
        "\n",
        "    X_aug = np.array(X_aug_list)\n",
        "    y_aug = y[aug_idx]\n",
        "\n",
        "    return np.vstack([X, X_aug]), np.hstack([y, y_aug])\n",
        "\n",
        "def build_lightweight_model(input_dim):\n",
        "    \"\"\"Build optimized lightweight model (56â†’28â†’1)\"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(56, activation='relu', input_shape=(input_dim,), kernel_initializer='he_normal'),\n",
        "        layers.Dropout(0.35),\n",
        "        layers.Dense(28, activation='relu', kernel_initializer='he_normal'),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_lightweight_model(train_features_df, test_features_df, epochs=40, verbose=True):\n",
        "    \"\"\"Train optimized lightweight model\"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Optimized Lightweight Model Training (56â†’28â†’1)\")\n",
        "\n",
        "    # Prepare data\n",
        "    feature_cols = [col for col in train_features_df.columns\n",
        "                   if col not in ['filename', 'category', 'is_normal', 'fold']]\n",
        "\n",
        "    X_train = train_features_df[feature_cols].values\n",
        "    y_train = train_features_df['is_normal'].values\n",
        "    X_test = test_features_df[feature_cols].values\n",
        "    y_test = test_features_df['is_normal'].values\n",
        "\n",
        "    # Data standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_train_scaled = np.nan_to_num(X_train_scaled, 0)\n",
        "    X_test_scaled = np.nan_to_num(X_test_scaled, 0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Training set: {X_train.shape}, Anomaly rate: {(1-np.mean(y_train))*100:.1f}%\")\n",
        "        print(f\"Test set: {X_test.shape}, Anomaly rate: {(1-np.mean(y_test))*100:.1f}%\")\n",
        "\n",
        "    # Enhanced data augmentation\n",
        "    X_train_aug, y_train_aug = smart_data_augmentation(X_train_scaled, y_train, factor=2.5)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Data augmentation: {len(X_train_scaled)} -> {len(X_train_aug)} samples\")\n",
        "\n",
        "    # Build and compile model\n",
        "    model = build_lightweight_model(X_train_scaled.shape[1])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Optimized callbacks\n",
        "    callbacks_list = [\n",
        "        callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=0),\n",
        "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=6, min_lr=1e-7, verbose=0)\n",
        "    ]\n",
        "\n",
        "    # Class weights - focus on anomaly detection optimization\n",
        "    class_weight = {\n",
        "        0: 2.0,  # Increased weight for anomaly class\n",
        "        1: 1.0   # Normal class weight\n",
        "    }\n",
        "\n",
        "    # Train model\n",
        "    if verbose:\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_aug, y_train_aug,\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        class_weight=class_weight,  # Add class weights\n",
        "        callbacks=callbacks_list,\n",
        "        verbose=1 if verbose else 0\n",
        "    )\n",
        "\n",
        "    # Test set evaluation\n",
        "    test_probs = model.predict(X_test_scaled, verbose=0).flatten()\n",
        "    test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "    # Overall metrics\n",
        "    test_metrics = {\n",
        "        'accuracy': accuracy_score(y_test, test_preds),\n",
        "        'auc': roc_auc_score(y_test, test_probs)\n",
        "    }\n",
        "\n",
        "    # Normal class metrics (label=1)\n",
        "    normal_metrics = {\n",
        "        'precision': precision_score(y_test, test_preds, pos_label=1, zero_division=0),\n",
        "        'recall': recall_score(y_test, test_preds, pos_label=1, zero_division=0),\n",
        "        'f1': f1_score(y_test, test_preds, pos_label=1, zero_division=0)\n",
        "    }\n",
        "\n",
        "    # Anomaly class metrics (label=0)\n",
        "    anomaly_metrics = {\n",
        "        'precision': precision_score(y_test, test_preds, pos_label=0, zero_division=0),\n",
        "        'recall': recall_score(y_test, test_preds, pos_label=0, zero_division=0),\n",
        "        'f1': f1_score(y_test, test_preds, pos_label=0, zero_division=0)\n",
        "    }\n",
        "\n",
        "    # Model information\n",
        "    total_params = model.count_params()\n",
        "    model_size_kb = total_params * 4 / 1024\n",
        "\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nModel Information:\")\n",
        "        print(f\"  Structure: 56â†’28â†’1, Parameters: {total_params:,}, Size: {model_size_kb:.1f}KB\")\n",
        "        print(f\"  Training epochs: {len(history.history['loss'])}\")\n",
        "\n",
        "        print(f\"\\nTest Results:\")\n",
        "        print(f\"  Accuracy: {test_metrics['accuracy']:.3f}, AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        print(f\"\\nNormal Class (Label=1):\")\n",
        "        print(f\"  Precision: {normal_metrics['precision']:.3f}\")\n",
        "        print(f\"  Recall: {normal_metrics['recall']:.3f}\")\n",
        "        print(f\"  F1: {normal_metrics['f1']:.3f}\")\n",
        "\n",
        "        print(f\"\\nAnomaly Class (Label=0):\")\n",
        "        print(f\"  Precision: {anomaly_metrics['precision']:.3f}\")\n",
        "        print(f\"  Recall: {anomaly_metrics['recall']:.3f}\")\n",
        "        print(f\"  F1: {anomaly_metrics['f1']:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'scaler': scaler,\n",
        "        'history': history.history,\n",
        "        'test_metrics': test_metrics,\n",
        "        'normal_metrics': normal_metrics,\n",
        "        'anomaly_metrics': anomaly_metrics,\n",
        "        'feature_columns': feature_cols,\n",
        "        'model_info': {\n",
        "            'structure': '56â†’28â†’1',\n",
        "            'total_params': total_params,\n",
        "            'size_kb': model_size_kb,\n",
        "            'hardware_friendly': True,\n",
        "            'optimizations': ['Class weight 2.0x', 'Enhanced data augmentation 3.0x', 'Learning rate optimization']\n",
        "        }\n",
        "    }\n",
        "\n",
        "def run_lightweight_training(features_df, test_size=0.2, epochs=40):\n",
        "    \"\"\"Run optimized lightweight model training\"\"\"\n",
        "\n",
        "    print(\"Optimized Lightweight Model Training (56â†’28â†’1)\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Split data\n",
        "    train_features_df, test_features_df = train_test_split(\n",
        "        features_df,\n",
        "        test_size=test_size,\n",
        "        stratify=features_df['is_normal'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(train_features_df)} samples, Test set: {len(test_features_df)} samples\")\n",
        "\n",
        "    # Train model\n",
        "    result = train_lightweight_model(\n",
        "        train_features_df, test_features_df,\n",
        "        epochs=epochs, verbose=True\n",
        "    )\n",
        "\n",
        "    # Summary\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"  Structure: {result['model_info']['structure']}\")\n",
        "    print(f\"  Parameters: {result['model_info']['total_params']:,}\")\n",
        "    print(f\"  Size: {result['model_info']['size_kb']:.1f}KB\")\n",
        "    print(f\"  Overall F1: {(result['normal_metrics']['f1'] + result['anomaly_metrics']['f1'])/2:.3f}\")\n",
        "    print(f\"  Normal Class F1: {result['normal_metrics']['f1']:.3f}\")\n",
        "    print(f\"  Anomaly Class F1: {result['anomaly_metrics']['f1']:.3f}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def plot_training_history(history_dict, save_path=\"figure_5_4_training_curves.png\"):\n",
        "\n",
        "    print(f\"\\nGenerating and saving training history plot to '{save_path}'...\")\n",
        "\n",
        "    # Set plotting style\n",
        "    sns.set_style(\"whitegrid\")\n",
        "\n",
        "    # Get data from the history dictionary\n",
        "    acc = history_dict.get('accuracy', [])\n",
        "    val_acc = history_dict.get('val_accuracy', [])\n",
        "    loss = history_dict.get('loss', [])\n",
        "    val_loss = history_dict.get('val_loss', [])\n",
        "\n",
        "    # Create a figure with two subplots (stacked vertically)\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "    # --- Subplot 1: Accuracy ---\n",
        "    ax1.plot(acc, label='Training Accuracy', color='blue', marker='o', linestyle='-')\n",
        "    ax1.plot(val_acc, label='Validation Accuracy', color='orange', marker='x', linestyle='--')\n",
        "    ax1.set_title('Model Accuracy over Epochs', fontsize=16)\n",
        "    ax1.set_ylabel('Accuracy', fontsize=12)\n",
        "    ax1.legend(loc='lower right')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # --- Subplot 2: Loss ---\n",
        "    ax2.plot(loss, label='Training Loss', color='blue', marker='o', linestyle='-')\n",
        "    ax2.plot(val_loss, label='Validation Loss', color='orange', marker='x', linestyle='--')\n",
        "    ax2.set_title('Model Loss over Epochs', fontsize=16)\n",
        "    ax2.set_ylabel('Loss', fontsize=12)\n",
        "    ax2.set_xlabel('Epoch', fontsize=12)\n",
        "    ax2.legend(loc='upper right')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Adjust layout and save the figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lAVo7rZ7kX54",
        "outputId": "d9db6e96-d864-48a3-9a87-35e22c2dcb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== Starting Run 1/5 ======\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "========================================\n",
            "Training set: 1600 samples, Test set: 400 samples\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "Training set: (1600, 85), Anomaly rate: 28.0%\n",
            "Test set: (400, 85), Anomaly rate: 28.0%\n",
            "Data augmentation: 1600 -> 2720 samples\n",
            "Starting training...\n",
            "Epoch 1/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4804 - loss: 1.1812 - val_accuracy: 0.9062 - val_loss: 0.4208 - learning_rate: 5.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5162 - loss: 1.0579 - val_accuracy: 0.9173 - val_loss: 0.4031 - learning_rate: 5.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5564 - loss: 0.9973 - val_accuracy: 0.9228 - val_loss: 0.4061 - learning_rate: 5.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5819 - loss: 0.9521 - val_accuracy: 0.9210 - val_loss: 0.3921 - learning_rate: 5.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5962 - loss: 0.9032 - val_accuracy: 0.9173 - val_loss: 0.3831 - learning_rate: 5.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5959 - loss: 0.9044 - val_accuracy: 0.9154 - val_loss: 0.3793 - learning_rate: 5.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5873 - loss: 0.9016 - val_accuracy: 0.9154 - val_loss: 0.3855 - learning_rate: 5.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6310 - loss: 0.8587 - val_accuracy: 0.9191 - val_loss: 0.3769 - learning_rate: 5.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6478 - loss: 0.8201 - val_accuracy: 0.9099 - val_loss: 0.3806 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6449 - loss: 0.8118 - val_accuracy: 0.9210 - val_loss: 0.3555 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6451 - loss: 0.8232 - val_accuracy: 0.9044 - val_loss: 0.3675 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6599 - loss: 0.7749 - val_accuracy: 0.9062 - val_loss: 0.3518 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6822 - loss: 0.7842 - val_accuracy: 0.9118 - val_loss: 0.3341 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6948 - loss: 0.7556 - val_accuracy: 0.9062 - val_loss: 0.3333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6945 - loss: 0.7449 - val_accuracy: 0.8897 - val_loss: 0.3292 - learning_rate: 5.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6907 - loss: 0.7463 - val_accuracy: 0.8897 - val_loss: 0.3332 - learning_rate: 5.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6893 - loss: 0.7478 - val_accuracy: 0.8952 - val_loss: 0.3222 - learning_rate: 5.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.7207 - val_accuracy: 0.9007 - val_loss: 0.3164 - learning_rate: 5.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7081 - loss: 0.7247 - val_accuracy: 0.9007 - val_loss: 0.3181 - learning_rate: 5.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.7357 - val_accuracy: 0.8971 - val_loss: 0.3117 - learning_rate: 5.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7265 - loss: 0.6810 - val_accuracy: 0.8897 - val_loss: 0.3071 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7233 - loss: 0.6969 - val_accuracy: 0.8915 - val_loss: 0.3001 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.6754 - val_accuracy: 0.8989 - val_loss: 0.2960 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.6797 - val_accuracy: 0.9099 - val_loss: 0.2770 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7560 - loss: 0.6499 - val_accuracy: 0.8971 - val_loss: 0.2866 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7530 - loss: 0.6194 - val_accuracy: 0.9062 - val_loss: 0.2749 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.6692 - val_accuracy: 0.9118 - val_loss: 0.2741 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.6450 - val_accuracy: 0.9118 - val_loss: 0.2655 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7529 - loss: 0.6634 - val_accuracy: 0.9044 - val_loss: 0.2676 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.6616 - val_accuracy: 0.9081 - val_loss: 0.2649 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7709 - loss: 0.6117 - val_accuracy: 0.9118 - val_loss: 0.2541 - learning_rate: 5.0000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.6306 - val_accuracy: 0.9136 - val_loss: 0.2554 - learning_rate: 5.0000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.6176 - val_accuracy: 0.9081 - val_loss: 0.2526 - learning_rate: 5.0000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7745 - loss: 0.5681 - val_accuracy: 0.9062 - val_loss: 0.2536 - learning_rate: 5.0000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.5949 - val_accuracy: 0.9062 - val_loss: 0.2557 - learning_rate: 5.0000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.5675 - val_accuracy: 0.9099 - val_loss: 0.2418 - learning_rate: 5.0000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7932 - loss: 0.5776 - val_accuracy: 0.9173 - val_loss: 0.2409 - learning_rate: 5.0000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7867 - loss: 0.5811 - val_accuracy: 0.9210 - val_loss: 0.2396 - learning_rate: 5.0000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7890 - loss: 0.5675 - val_accuracy: 0.9136 - val_loss: 0.2415 - learning_rate: 5.0000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7936 - loss: 0.5537 - val_accuracy: 0.9154 - val_loss: 0.2302 - learning_rate: 5.0000e-04\n",
            "Epoch 41/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7942 - loss: 0.5592 - val_accuracy: 0.9265 - val_loss: 0.2291 - learning_rate: 5.0000e-04\n",
            "Epoch 42/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.5539 - val_accuracy: 0.9265 - val_loss: 0.2190 - learning_rate: 5.0000e-04\n",
            "Epoch 43/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.5438 - val_accuracy: 0.9357 - val_loss: 0.2120 - learning_rate: 5.0000e-04\n",
            "Epoch 44/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7927 - loss: 0.5612 - val_accuracy: 0.9357 - val_loss: 0.2121 - learning_rate: 5.0000e-04\n",
            "Epoch 45/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.5347 - val_accuracy: 0.9320 - val_loss: 0.2206 - learning_rate: 5.0000e-04\n",
            "Epoch 46/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.5326 - val_accuracy: 0.9412 - val_loss: 0.2065 - learning_rate: 5.0000e-04\n",
            "Epoch 47/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.5541 - val_accuracy: 0.9430 - val_loss: 0.2048 - learning_rate: 5.0000e-04\n",
            "Epoch 48/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.5209 - val_accuracy: 0.9338 - val_loss: 0.2117 - learning_rate: 5.0000e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.5336 - val_accuracy: 0.9393 - val_loss: 0.1993 - learning_rate: 5.0000e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.5209 - val_accuracy: 0.9338 - val_loss: 0.1991 - learning_rate: 5.0000e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.5208 - val_accuracy: 0.9412 - val_loss: 0.1961 - learning_rate: 5.0000e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.5049 - val_accuracy: 0.9357 - val_loss: 0.1976 - learning_rate: 5.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.5022 - val_accuracy: 0.9467 - val_loss: 0.1876 - learning_rate: 5.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.4829 - val_accuracy: 0.9449 - val_loss: 0.1816 - learning_rate: 5.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8328 - loss: 0.4765 - val_accuracy: 0.9449 - val_loss: 0.1839 - learning_rate: 5.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.4723 - val_accuracy: 0.9357 - val_loss: 0.1913 - learning_rate: 5.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.4698 - val_accuracy: 0.9412 - val_loss: 0.1773 - learning_rate: 5.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.4757 - val_accuracy: 0.9430 - val_loss: 0.1835 - learning_rate: 5.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.4557 - val_accuracy: 0.9467 - val_loss: 0.1702 - learning_rate: 5.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8388 - loss: 0.4767 - val_accuracy: 0.9485 - val_loss: 0.1727 - learning_rate: 5.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.4469 - val_accuracy: 0.9485 - val_loss: 0.1681 - learning_rate: 5.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8417 - loss: 0.4639 - val_accuracy: 0.9467 - val_loss: 0.1692 - learning_rate: 5.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8389 - loss: 0.4760 - val_accuracy: 0.9504 - val_loss: 0.1696 - learning_rate: 5.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8318 - loss: 0.4591 - val_accuracy: 0.9596 - val_loss: 0.1584 - learning_rate: 5.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8423 - loss: 0.4382 - val_accuracy: 0.9632 - val_loss: 0.1539 - learning_rate: 5.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8506 - loss: 0.4172 - val_accuracy: 0.9614 - val_loss: 0.1449 - learning_rate: 5.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.4322 - val_accuracy: 0.9614 - val_loss: 0.1553 - learning_rate: 5.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.4362 - val_accuracy: 0.9577 - val_loss: 0.1547 - learning_rate: 5.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8484 - loss: 0.4235 - val_accuracy: 0.9559 - val_loss: 0.1550 - learning_rate: 5.0000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.4543 - val_accuracy: 0.9559 - val_loss: 0.1528 - learning_rate: 5.0000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.4171 - val_accuracy: 0.9540 - val_loss: 0.1514 - learning_rate: 5.0000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.4139 - val_accuracy: 0.9577 - val_loss: 0.1478 - learning_rate: 5.0000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.4276 - val_accuracy: 0.9559 - val_loss: 0.1503 - learning_rate: 1.5000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 0.4210 - val_accuracy: 0.9577 - val_loss: 0.1481 - learning_rate: 1.5000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.3851 - val_accuracy: 0.9577 - val_loss: 0.1489 - learning_rate: 1.5000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.4126 - val_accuracy: 0.9577 - val_loss: 0.1532 - learning_rate: 1.5000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.3880 - val_accuracy: 0.9577 - val_loss: 0.1473 - learning_rate: 1.5000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3952 - val_accuracy: 0.9577 - val_loss: 0.1496 - learning_rate: 1.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Information:\n",
            "  Structure: 56â†’28â†’1, Parameters: 6,441, Size: 25.2KB\n",
            "  Training epochs: 78\n",
            "\n",
            "Test Results:\n",
            "  Accuracy: 0.812, AUC: 0.901\n",
            "\n",
            "Normal Class (Label=1):\n",
            "  Precision: 0.946\n",
            "  Recall: 0.785\n",
            "  F1: 0.858\n",
            "\n",
            "Anomaly Class (Label=0):\n",
            "  Precision: 0.615\n",
            "  Recall: 0.884\n",
            "  F1: 0.725\n",
            "\n",
            "Summary:\n",
            "  Structure: 56â†’28â†’1\n",
            "  Parameters: 6,441\n",
            "  Size: 25.2KB\n",
            "  Overall F1: 0.791\n",
            "  Normal Class F1: 0.858\n",
            "  Anomaly Class F1: 0.725\n",
            "\n",
            "New best model saved (Average F1: 0.791)\n",
            "\n",
            "====== Starting Run 2/5 ======\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "========================================\n",
            "Training set: 1600 samples, Test set: 400 samples\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "Training set: (1600, 85), Anomaly rate: 28.0%\n",
            "Test set: (400, 85), Anomaly rate: 28.0%\n",
            "Data augmentation: 1600 -> 2720 samples\n",
            "Starting training...\n",
            "Epoch 1/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5271 - loss: 1.3660 - val_accuracy: 0.9320 - val_loss: 0.3050 - learning_rate: 5.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5388 - loss: 1.0861 - val_accuracy: 0.9320 - val_loss: 0.3154 - learning_rate: 5.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5556 - loss: 1.0138 - val_accuracy: 0.9504 - val_loss: 0.3044 - learning_rate: 5.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5730 - loss: 0.9568 - val_accuracy: 0.9467 - val_loss: 0.3076 - learning_rate: 5.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6029 - loss: 0.9341 - val_accuracy: 0.9485 - val_loss: 0.3041 - learning_rate: 5.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6167 - loss: 0.9079 - val_accuracy: 0.9412 - val_loss: 0.3092 - learning_rate: 5.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.8589 - val_accuracy: 0.9504 - val_loss: 0.2882 - learning_rate: 5.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6177 - loss: 0.8563 - val_accuracy: 0.9467 - val_loss: 0.2880 - learning_rate: 5.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6462 - loss: 0.8178 - val_accuracy: 0.9467 - val_loss: 0.2889 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6518 - loss: 0.8109 - val_accuracy: 0.9485 - val_loss: 0.2893 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6631 - loss: 0.8040 - val_accuracy: 0.9485 - val_loss: 0.2850 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6794 - loss: 0.7737 - val_accuracy: 0.9522 - val_loss: 0.2708 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6688 - loss: 0.7782 - val_accuracy: 0.9467 - val_loss: 0.2792 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6829 - loss: 0.7543 - val_accuracy: 0.9449 - val_loss: 0.2679 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 0.7428 - val_accuracy: 0.9449 - val_loss: 0.2624 - learning_rate: 5.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6989 - loss: 0.7396 - val_accuracy: 0.9430 - val_loss: 0.2655 - learning_rate: 5.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 0.7243 - val_accuracy: 0.9577 - val_loss: 0.2451 - learning_rate: 5.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7046 - loss: 0.7089 - val_accuracy: 0.9559 - val_loss: 0.2478 - learning_rate: 5.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.6972 - val_accuracy: 0.9522 - val_loss: 0.2459 - learning_rate: 5.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7142 - loss: 0.7283 - val_accuracy: 0.9559 - val_loss: 0.2340 - learning_rate: 5.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.7141 - val_accuracy: 0.9577 - val_loss: 0.2349 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7301 - loss: 0.7001 - val_accuracy: 0.9596 - val_loss: 0.2324 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.6937 - val_accuracy: 0.9614 - val_loss: 0.2370 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7312 - loss: 0.6802 - val_accuracy: 0.9651 - val_loss: 0.2273 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7415 - loss: 0.6574 - val_accuracy: 0.9614 - val_loss: 0.2271 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7560 - loss: 0.6382 - val_accuracy: 0.9651 - val_loss: 0.2171 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7493 - loss: 0.6540 - val_accuracy: 0.9632 - val_loss: 0.2145 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7516 - loss: 0.6211 - val_accuracy: 0.9614 - val_loss: 0.2100 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.6406 - val_accuracy: 0.9651 - val_loss: 0.2072 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7614 - loss: 0.6172 - val_accuracy: 0.9614 - val_loss: 0.2170 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.6313 - val_accuracy: 0.9706 - val_loss: 0.2038 - learning_rate: 5.0000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7679 - loss: 0.6040 - val_accuracy: 0.9706 - val_loss: 0.1985 - learning_rate: 5.0000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7529 - loss: 0.6238 - val_accuracy: 0.9706 - val_loss: 0.1936 - learning_rate: 5.0000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.6493 - val_accuracy: 0.9706 - val_loss: 0.1997 - learning_rate: 5.0000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.5607 - val_accuracy: 0.9651 - val_loss: 0.2015 - learning_rate: 5.0000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.5815 - val_accuracy: 0.9688 - val_loss: 0.1878 - learning_rate: 5.0000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.5779 - val_accuracy: 0.9706 - val_loss: 0.1802 - learning_rate: 5.0000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7890 - loss: 0.5835 - val_accuracy: 0.9706 - val_loss: 0.1782 - learning_rate: 5.0000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.5687 - val_accuracy: 0.9706 - val_loss: 0.1842 - learning_rate: 5.0000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.5761 - val_accuracy: 0.9706 - val_loss: 0.1849 - learning_rate: 5.0000e-04\n",
            "Epoch 41/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7828 - loss: 0.5699 - val_accuracy: 0.9706 - val_loss: 0.1762 - learning_rate: 5.0000e-04\n",
            "Epoch 42/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.5433 - val_accuracy: 0.9706 - val_loss: 0.1716 - learning_rate: 5.0000e-04\n",
            "Epoch 43/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.5243 - val_accuracy: 0.9688 - val_loss: 0.1730 - learning_rate: 5.0000e-04\n",
            "Epoch 44/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8164 - loss: 0.5371 - val_accuracy: 0.9706 - val_loss: 0.1674 - learning_rate: 5.0000e-04\n",
            "Epoch 45/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.5420 - val_accuracy: 0.9706 - val_loss: 0.1611 - learning_rate: 5.0000e-04\n",
            "Epoch 46/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.5462 - val_accuracy: 0.9706 - val_loss: 0.1670 - learning_rate: 5.0000e-04\n",
            "Epoch 47/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.5318 - val_accuracy: 0.9688 - val_loss: 0.1569 - learning_rate: 5.0000e-04\n",
            "Epoch 48/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.5082 - val_accuracy: 0.9688 - val_loss: 0.1507 - learning_rate: 5.0000e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8040 - loss: 0.5338 - val_accuracy: 0.9688 - val_loss: 0.1547 - learning_rate: 5.0000e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8043 - loss: 0.5229 - val_accuracy: 0.9688 - val_loss: 0.1597 - learning_rate: 5.0000e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8181 - loss: 0.5125 - val_accuracy: 0.9688 - val_loss: 0.1568 - learning_rate: 5.0000e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8276 - loss: 0.4912 - val_accuracy: 0.9761 - val_loss: 0.1490 - learning_rate: 5.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.5302 - val_accuracy: 0.9688 - val_loss: 0.1528 - learning_rate: 5.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8314 - loss: 0.4910 - val_accuracy: 0.9743 - val_loss: 0.1399 - learning_rate: 5.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.4760 - val_accuracy: 0.9761 - val_loss: 0.1379 - learning_rate: 5.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.4744 - val_accuracy: 0.9761 - val_loss: 0.1346 - learning_rate: 5.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 0.4821 - val_accuracy: 0.9835 - val_loss: 0.1321 - learning_rate: 5.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.5186 - val_accuracy: 0.9761 - val_loss: 0.1317 - learning_rate: 5.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4864 - val_accuracy: 0.9798 - val_loss: 0.1315 - learning_rate: 5.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8353 - loss: 0.4584 - val_accuracy: 0.9835 - val_loss: 0.1365 - learning_rate: 5.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.4580 - val_accuracy: 0.9853 - val_loss: 0.1277 - learning_rate: 5.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8392 - loss: 0.4487 - val_accuracy: 0.9835 - val_loss: 0.1340 - learning_rate: 5.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.4213 - val_accuracy: 0.9871 - val_loss: 0.1316 - learning_rate: 5.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.4536 - val_accuracy: 0.9890 - val_loss: 0.1227 - learning_rate: 5.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.4279 - val_accuracy: 0.9853 - val_loss: 0.1221 - learning_rate: 5.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.4078 - val_accuracy: 0.9908 - val_loss: 0.1152 - learning_rate: 5.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.4390 - val_accuracy: 0.9871 - val_loss: 0.1147 - learning_rate: 5.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.4168 - val_accuracy: 0.9871 - val_loss: 0.1109 - learning_rate: 5.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.4474 - val_accuracy: 0.9853 - val_loss: 0.1091 - learning_rate: 5.0000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.4215 - val_accuracy: 0.9890 - val_loss: 0.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.4279 - val_accuracy: 0.9890 - val_loss: 0.1055 - learning_rate: 5.0000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8495 - loss: 0.4227 - val_accuracy: 0.9853 - val_loss: 0.1108 - learning_rate: 5.0000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8538 - loss: 0.4167 - val_accuracy: 0.9871 - val_loss: 0.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8497 - loss: 0.4272 - val_accuracy: 0.9908 - val_loss: 0.0994 - learning_rate: 5.0000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8729 - loss: 0.3785 - val_accuracy: 0.9926 - val_loss: 0.0969 - learning_rate: 5.0000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.4182 - val_accuracy: 0.9926 - val_loss: 0.0955 - learning_rate: 5.0000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8522 - loss: 0.3897 - val_accuracy: 0.9908 - val_loss: 0.0960 - learning_rate: 5.0000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.3971 - val_accuracy: 0.9926 - val_loss: 0.0957 - learning_rate: 5.0000e-04\n",
            "Epoch 79/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8651 - loss: 0.3987 - val_accuracy: 0.9926 - val_loss: 0.0932 - learning_rate: 5.0000e-04\n",
            "Epoch 80/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.3996 - val_accuracy: 0.9926 - val_loss: 0.0899 - learning_rate: 5.0000e-04\n",
            "Epoch 81/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8610 - loss: 0.3853 - val_accuracy: 0.9926 - val_loss: 0.0917 - learning_rate: 5.0000e-04\n",
            "Epoch 82/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8653 - loss: 0.3790 - val_accuracy: 0.9926 - val_loss: 0.0903 - learning_rate: 5.0000e-04\n",
            "Epoch 83/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8775 - loss: 0.3745 - val_accuracy: 0.9926 - val_loss: 0.0868 - learning_rate: 5.0000e-04\n",
            "Epoch 84/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8717 - loss: 0.3727 - val_accuracy: 0.9926 - val_loss: 0.0884 - learning_rate: 5.0000e-04\n",
            "Epoch 85/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8751 - loss: 0.3688 - val_accuracy: 0.9963 - val_loss: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 86/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3623 - val_accuracy: 0.9945 - val_loss: 0.0829 - learning_rate: 5.0000e-04\n",
            "Epoch 87/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8694 - loss: 0.3821 - val_accuracy: 0.9926 - val_loss: 0.0848 - learning_rate: 5.0000e-04\n",
            "Epoch 88/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.3834 - val_accuracy: 0.9926 - val_loss: 0.0885 - learning_rate: 5.0000e-04\n",
            "Epoch 89/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.3711 - val_accuracy: 0.9908 - val_loss: 0.0779 - learning_rate: 5.0000e-04\n",
            "Epoch 90/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.3840 - val_accuracy: 0.9908 - val_loss: 0.0837 - learning_rate: 5.0000e-04\n",
            "Epoch 91/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.3503 - val_accuracy: 0.9926 - val_loss: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 92/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8869 - loss: 0.3501 - val_accuracy: 0.9926 - val_loss: 0.0771 - learning_rate: 5.0000e-04\n",
            "Epoch 93/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8815 - loss: 0.3456 - val_accuracy: 0.9926 - val_loss: 0.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 94/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8770 - loss: 0.3821 - val_accuracy: 0.9926 - val_loss: 0.0788 - learning_rate: 5.0000e-04\n",
            "Epoch 95/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8873 - loss: 0.3442 - val_accuracy: 0.9926 - val_loss: 0.0801 - learning_rate: 5.0000e-04\n",
            "Epoch 96/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8818 - loss: 0.3482 - val_accuracy: 0.9926 - val_loss: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 97/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.3153 - val_accuracy: 0.9926 - val_loss: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 98/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.3214 - val_accuracy: 0.9945 - val_loss: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 99/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8853 - loss: 0.3304 - val_accuracy: 0.9963 - val_loss: 0.0762 - learning_rate: 5.0000e-04\n",
            "Epoch 100/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.3424 - val_accuracy: 0.9963 - val_loss: 0.0727 - learning_rate: 5.0000e-04\n",
            "Epoch 101/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 0.3156 - val_accuracy: 0.9963 - val_loss: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 102/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.3394 - val_accuracy: 0.9963 - val_loss: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 103/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8980 - loss: 0.3238 - val_accuracy: 0.9963 - val_loss: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 104/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8932 - loss: 0.3222 - val_accuracy: 0.9963 - val_loss: 0.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 105/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.3205 - val_accuracy: 0.9963 - val_loss: 0.0609 - learning_rate: 5.0000e-04\n",
            "Epoch 106/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.3051 - val_accuracy: 0.9963 - val_loss: 0.0588 - learning_rate: 5.0000e-04\n",
            "Epoch 107/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8888 - loss: 0.3315 - val_accuracy: 0.9963 - val_loss: 0.0602 - learning_rate: 5.0000e-04\n",
            "Epoch 108/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8791 - loss: 0.3352 - val_accuracy: 0.9926 - val_loss: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 109/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.3079 - val_accuracy: 0.9963 - val_loss: 0.0571 - learning_rate: 5.0000e-04\n",
            "Epoch 110/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8941 - loss: 0.3088 - val_accuracy: 0.9963 - val_loss: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 111/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.3057 - val_accuracy: 0.9963 - val_loss: 0.0550 - learning_rate: 5.0000e-04\n",
            "Epoch 112/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2815 - val_accuracy: 0.9963 - val_loss: 0.0519 - learning_rate: 5.0000e-04\n",
            "Epoch 113/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9015 - loss: 0.3275 - val_accuracy: 0.9963 - val_loss: 0.0564 - learning_rate: 5.0000e-04\n",
            "Epoch 114/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.3559 - val_accuracy: 0.9963 - val_loss: 0.0567 - learning_rate: 5.0000e-04\n",
            "Epoch 115/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.2852 - val_accuracy: 0.9963 - val_loss: 0.0529 - learning_rate: 5.0000e-04\n",
            "Epoch 116/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.2589 - val_accuracy: 0.9963 - val_loss: 0.0493 - learning_rate: 5.0000e-04\n",
            "Epoch 117/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8937 - loss: 0.3045 - val_accuracy: 0.9963 - val_loss: 0.0520 - learning_rate: 5.0000e-04\n",
            "Epoch 118/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9120 - loss: 0.2766 - val_accuracy: 0.9963 - val_loss: 0.0504 - learning_rate: 5.0000e-04\n",
            "Epoch 119/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9106 - loss: 0.2899 - val_accuracy: 0.9963 - val_loss: 0.0472 - learning_rate: 5.0000e-04\n",
            "Epoch 120/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9006 - loss: 0.3176 - val_accuracy: 0.9963 - val_loss: 0.0502 - learning_rate: 5.0000e-04\n",
            "Epoch 121/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9161 - loss: 0.2689 - val_accuracy: 0.9963 - val_loss: 0.0466 - learning_rate: 5.0000e-04\n",
            "Epoch 122/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9108 - loss: 0.3071 - val_accuracy: 0.9963 - val_loss: 0.0454 - learning_rate: 5.0000e-04\n",
            "Epoch 123/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9214 - loss: 0.2476 - val_accuracy: 0.9963 - val_loss: 0.0481 - learning_rate: 5.0000e-04\n",
            "Epoch 124/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9028 - loss: 0.2924 - val_accuracy: 0.9963 - val_loss: 0.0427 - learning_rate: 5.0000e-04\n",
            "Epoch 125/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.2626 - val_accuracy: 0.9963 - val_loss: 0.0434 - learning_rate: 5.0000e-04\n",
            "Epoch 126/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2861 - val_accuracy: 0.9963 - val_loss: 0.0462 - learning_rate: 5.0000e-04\n",
            "Epoch 127/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9081 - loss: 0.2927 - val_accuracy: 0.9963 - val_loss: 0.0459 - learning_rate: 5.0000e-04\n",
            "Epoch 128/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.2463 - val_accuracy: 0.9963 - val_loss: 0.0486 - learning_rate: 5.0000e-04\n",
            "Epoch 129/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2552 - val_accuracy: 0.9963 - val_loss: 0.0420 - learning_rate: 5.0000e-04\n",
            "Epoch 130/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.2486 - val_accuracy: 0.9963 - val_loss: 0.0398 - learning_rate: 5.0000e-04\n",
            "Epoch 131/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.2363 - val_accuracy: 0.9963 - val_loss: 0.0444 - learning_rate: 5.0000e-04\n",
            "Epoch 132/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2569 - val_accuracy: 0.9963 - val_loss: 0.0401 - learning_rate: 5.0000e-04\n",
            "Epoch 133/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9149 - loss: 0.2366 - val_accuracy: 0.9963 - val_loss: 0.0429 - learning_rate: 5.0000e-04\n",
            "Epoch 134/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.2558 - val_accuracy: 0.9963 - val_loss: 0.0405 - learning_rate: 5.0000e-04\n",
            "Epoch 135/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2503 - val_accuracy: 0.9963 - val_loss: 0.0434 - learning_rate: 5.0000e-04\n",
            "Epoch 136/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2529 - val_accuracy: 0.9963 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 137/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2385 - val_accuracy: 0.9963 - val_loss: 0.0382 - learning_rate: 5.0000e-04\n",
            "Epoch 138/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1811 - val_accuracy: 0.9963 - val_loss: 0.0373 - learning_rate: 5.0000e-04\n",
            "Epoch 139/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9175 - loss: 0.2406 - val_accuracy: 0.9963 - val_loss: 0.0357 - learning_rate: 5.0000e-04\n",
            "Epoch 140/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9291 - loss: 0.2179 - val_accuracy: 0.9963 - val_loss: 0.0358 - learning_rate: 5.0000e-04\n",
            "Epoch 141/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9220 - loss: 0.2532 - val_accuracy: 0.9963 - val_loss: 0.0369 - learning_rate: 5.0000e-04\n",
            "Epoch 142/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9157 - loss: 0.2423 - val_accuracy: 0.9963 - val_loss: 0.0375 - learning_rate: 5.0000e-04\n",
            "Epoch 143/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9241 - loss: 0.2514 - val_accuracy: 0.9963 - val_loss: 0.0402 - learning_rate: 5.0000e-04\n",
            "Epoch 144/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9291 - loss: 0.2251 - val_accuracy: 0.9963 - val_loss: 0.0350 - learning_rate: 5.0000e-04\n",
            "Epoch 145/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.2286 - val_accuracy: 0.9963 - val_loss: 0.0321 - learning_rate: 5.0000e-04\n",
            "Epoch 146/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2306 - val_accuracy: 0.9963 - val_loss: 0.0344 - learning_rate: 5.0000e-04\n",
            "Epoch 147/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9259 - loss: 0.2201 - val_accuracy: 0.9963 - val_loss: 0.0309 - learning_rate: 5.0000e-04\n",
            "Epoch 148/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9179 - loss: 0.2506 - val_accuracy: 0.9963 - val_loss: 0.0337 - learning_rate: 5.0000e-04\n",
            "Epoch 149/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1919 - val_accuracy: 0.9963 - val_loss: 0.0308 - learning_rate: 5.0000e-04\n",
            "Epoch 150/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.2099 - val_accuracy: 0.9963 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
            "Epoch 151/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1992 - val_accuracy: 0.9963 - val_loss: 0.0311 - learning_rate: 5.0000e-04\n",
            "Epoch 152/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9432 - loss: 0.1913 - val_accuracy: 0.9963 - val_loss: 0.0278 - learning_rate: 5.0000e-04\n",
            "Epoch 153/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.2127 - val_accuracy: 0.9963 - val_loss: 0.0266 - learning_rate: 5.0000e-04\n",
            "Epoch 154/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9196 - loss: 0.2771 - val_accuracy: 0.9963 - val_loss: 0.0283 - learning_rate: 5.0000e-04\n",
            "Epoch 155/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2195 - val_accuracy: 0.9963 - val_loss: 0.0298 - learning_rate: 5.0000e-04\n",
            "Epoch 156/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.2019 - val_accuracy: 0.9963 - val_loss: 0.0296 - learning_rate: 5.0000e-04\n",
            "Epoch 157/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9308 - loss: 0.2165 - val_accuracy: 0.9963 - val_loss: 0.0279 - learning_rate: 1.5000e-04\n",
            "Epoch 158/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.1704 - val_accuracy: 0.9963 - val_loss: 0.0295 - learning_rate: 1.5000e-04\n",
            "Epoch 159/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9449 - loss: 0.1792 - val_accuracy: 0.9963 - val_loss: 0.0279 - learning_rate: 1.5000e-04\n",
            "Epoch 160/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.2478 - val_accuracy: 0.9963 - val_loss: 0.0285 - learning_rate: 1.5000e-04\n",
            "Epoch 161/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.1859 - val_accuracy: 0.9963 - val_loss: 0.0282 - learning_rate: 1.5000e-04\n",
            "Epoch 162/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9321 - loss: 0.2145 - val_accuracy: 0.9963 - val_loss: 0.0264 - learning_rate: 1.5000e-04\n",
            "Epoch 163/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9360 - loss: 0.1948 - val_accuracy: 0.9963 - val_loss: 0.0251 - learning_rate: 1.5000e-04\n",
            "Epoch 164/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9378 - loss: 0.1906 - val_accuracy: 0.9963 - val_loss: 0.0263 - learning_rate: 1.5000e-04\n",
            "Epoch 165/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9371 - loss: 0.2050 - val_accuracy: 0.9963 - val_loss: 0.0254 - learning_rate: 1.5000e-04\n",
            "Epoch 166/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9426 - loss: 0.1864 - val_accuracy: 0.9963 - val_loss: 0.0252 - learning_rate: 1.5000e-04\n",
            "Epoch 167/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9390 - loss: 0.1888 - val_accuracy: 0.9963 - val_loss: 0.0246 - learning_rate: 1.5000e-04\n",
            "Epoch 168/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9291 - loss: 0.2069 - val_accuracy: 0.9963 - val_loss: 0.0261 - learning_rate: 1.5000e-04\n",
            "Epoch 169/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9483 - loss: 0.1708 - val_accuracy: 0.9963 - val_loss: 0.0258 - learning_rate: 1.5000e-04\n",
            "Epoch 170/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.1799 - val_accuracy: 0.9963 - val_loss: 0.0250 - learning_rate: 1.5000e-04\n",
            "Epoch 171/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1895 - val_accuracy: 0.9963 - val_loss: 0.0251 - learning_rate: 1.5000e-04\n",
            "Epoch 172/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.1858 - val_accuracy: 0.9963 - val_loss: 0.0249 - learning_rate: 1.5000e-04\n",
            "Epoch 173/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9413 - loss: 0.1982 - val_accuracy: 0.9963 - val_loss: 0.0256 - learning_rate: 1.5000e-04\n",
            "Epoch 174/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9325 - loss: 0.2021 - val_accuracy: 0.9963 - val_loss: 0.0267 - learning_rate: 4.5000e-05\n",
            "Epoch 175/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.2046 - val_accuracy: 0.9963 - val_loss: 0.0267 - learning_rate: 4.5000e-05\n",
            "Epoch 176/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 0.1910 - val_accuracy: 0.9963 - val_loss: 0.0259 - learning_rate: 4.5000e-05\n",
            "Epoch 177/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.1790 - val_accuracy: 0.9963 - val_loss: 0.0254 - learning_rate: 4.5000e-05\n",
            "Epoch 178/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9366 - loss: 0.1972 - val_accuracy: 0.9963 - val_loss: 0.0254 - learning_rate: 4.5000e-05\n",
            "Epoch 179/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.1892 - val_accuracy: 0.9963 - val_loss: 0.0255 - learning_rate: 4.5000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Information:\n",
            "  Structure: 56â†’28â†’1, Parameters: 6,441, Size: 25.2KB\n",
            "  Training epochs: 179\n",
            "\n",
            "Test Results:\n",
            "  Accuracy: 0.823, AUC: 0.894\n",
            "\n",
            "Normal Class (Label=1):\n",
            "  Precision: 0.909\n",
            "  Recall: 0.837\n",
            "  F1: 0.872\n",
            "\n",
            "Anomaly Class (Label=0):\n",
            "  Precision: 0.652\n",
            "  Recall: 0.786\n",
            "  F1: 0.713\n",
            "\n",
            "Summary:\n",
            "  Structure: 56â†’28â†’1\n",
            "  Parameters: 6,441\n",
            "  Size: 25.2KB\n",
            "  Overall F1: 0.792\n",
            "  Normal Class F1: 0.872\n",
            "  Anomaly Class F1: 0.713\n",
            "\n",
            "New best model saved (Average F1: 0.792)\n",
            "\n",
            "====== Starting Run 3/5 ======\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "========================================\n",
            "Training set: 1600 samples, Test set: 400 samples\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "Training set: (1600, 85), Anomaly rate: 28.0%\n",
            "Test set: (400, 85), Anomaly rate: 28.0%\n",
            "Data augmentation: 1600 -> 2720 samples\n",
            "Starting training...\n",
            "Epoch 1/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5182 - loss: 1.2822 - val_accuracy: 0.9357 - val_loss: 0.3562 - learning_rate: 5.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5332 - loss: 1.0707 - val_accuracy: 0.9301 - val_loss: 0.3498 - learning_rate: 5.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5633 - loss: 0.9961 - val_accuracy: 0.9430 - val_loss: 0.3400 - learning_rate: 5.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5807 - loss: 0.9878 - val_accuracy: 0.9301 - val_loss: 0.3509 - learning_rate: 5.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5844 - loss: 0.9125 - val_accuracy: 0.9393 - val_loss: 0.3486 - learning_rate: 5.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6043 - loss: 0.9005 - val_accuracy: 0.9430 - val_loss: 0.3458 - learning_rate: 5.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6157 - loss: 0.8950 - val_accuracy: 0.9449 - val_loss: 0.3342 - learning_rate: 5.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.8650 - val_accuracy: 0.9375 - val_loss: 0.3464 - learning_rate: 5.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6452 - loss: 0.8167 - val_accuracy: 0.9338 - val_loss: 0.3504 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6739 - loss: 0.8168 - val_accuracy: 0.9449 - val_loss: 0.3182 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6559 - loss: 0.8070 - val_accuracy: 0.9449 - val_loss: 0.3090 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6629 - loss: 0.7887 - val_accuracy: 0.9449 - val_loss: 0.3116 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6833 - loss: 0.7589 - val_accuracy: 0.9504 - val_loss: 0.3023 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6837 - loss: 0.7734 - val_accuracy: 0.9522 - val_loss: 0.2938 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6800 - loss: 0.7626 - val_accuracy: 0.9504 - val_loss: 0.2984 - learning_rate: 5.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7013 - loss: 0.7291 - val_accuracy: 0.9485 - val_loss: 0.2863 - learning_rate: 5.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6961 - loss: 0.7377 - val_accuracy: 0.9504 - val_loss: 0.2827 - learning_rate: 5.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7136 - loss: 0.7023 - val_accuracy: 0.9522 - val_loss: 0.2715 - learning_rate: 5.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7184 - loss: 0.7073 - val_accuracy: 0.9540 - val_loss: 0.2764 - learning_rate: 5.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7207 - loss: 0.6898 - val_accuracy: 0.9412 - val_loss: 0.2750 - learning_rate: 5.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.6924 - val_accuracy: 0.9467 - val_loss: 0.2615 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7233 - loss: 0.6804 - val_accuracy: 0.9504 - val_loss: 0.2591 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7241 - loss: 0.6786 - val_accuracy: 0.9522 - val_loss: 0.2511 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.6625 - val_accuracy: 0.9522 - val_loss: 0.2513 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7413 - loss: 0.6615 - val_accuracy: 0.9522 - val_loss: 0.2458 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7280 - loss: 0.6650 - val_accuracy: 0.9467 - val_loss: 0.2515 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7424 - loss: 0.6323 - val_accuracy: 0.9485 - val_loss: 0.2366 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 0.6407 - val_accuracy: 0.9467 - val_loss: 0.2327 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7631 - loss: 0.6077 - val_accuracy: 0.9559 - val_loss: 0.2299 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7458 - loss: 0.6287 - val_accuracy: 0.9559 - val_loss: 0.2220 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7566 - loss: 0.5958 - val_accuracy: 0.9596 - val_loss: 0.2252 - learning_rate: 5.0000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.5853 - val_accuracy: 0.9504 - val_loss: 0.2142 - learning_rate: 5.0000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6194 - val_accuracy: 0.9614 - val_loss: 0.2107 - learning_rate: 5.0000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.6025 - val_accuracy: 0.9651 - val_loss: 0.2033 - learning_rate: 5.0000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.6178 - val_accuracy: 0.9596 - val_loss: 0.2125 - learning_rate: 5.0000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.5774 - val_accuracy: 0.9504 - val_loss: 0.2175 - learning_rate: 5.0000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.5819 - val_accuracy: 0.9632 - val_loss: 0.2121 - learning_rate: 5.0000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.5391 - val_accuracy: 0.9632 - val_loss: 0.1959 - learning_rate: 5.0000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.5716 - val_accuracy: 0.9632 - val_loss: 0.1987 - learning_rate: 5.0000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.5555 - val_accuracy: 0.9651 - val_loss: 0.1959 - learning_rate: 5.0000e-04\n",
            "Epoch 41/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.5422 - val_accuracy: 0.9596 - val_loss: 0.1953 - learning_rate: 5.0000e-04\n",
            "Epoch 42/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.5453 - val_accuracy: 0.9669 - val_loss: 0.1918 - learning_rate: 5.0000e-04\n",
            "Epoch 43/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 0.5562 - val_accuracy: 0.9614 - val_loss: 0.1959 - learning_rate: 5.0000e-04\n",
            "Epoch 44/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.5475 - val_accuracy: 0.9706 - val_loss: 0.1868 - learning_rate: 5.0000e-04\n",
            "Epoch 45/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 0.5466 - val_accuracy: 0.9706 - val_loss: 0.1767 - learning_rate: 5.0000e-04\n",
            "Epoch 46/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.5451 - val_accuracy: 0.9596 - val_loss: 0.1852 - learning_rate: 5.0000e-04\n",
            "Epoch 47/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.5413 - val_accuracy: 0.9614 - val_loss: 0.1789 - learning_rate: 5.0000e-04\n",
            "Epoch 48/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.5322 - val_accuracy: 0.9540 - val_loss: 0.1841 - learning_rate: 5.0000e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.5099 - val_accuracy: 0.9669 - val_loss: 0.1753 - learning_rate: 5.0000e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4987 - val_accuracy: 0.9540 - val_loss: 0.1819 - learning_rate: 5.0000e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8138 - loss: 0.5168 - val_accuracy: 0.9743 - val_loss: 0.1647 - learning_rate: 5.0000e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8033 - loss: 0.5178 - val_accuracy: 0.9688 - val_loss: 0.1649 - learning_rate: 5.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8121 - loss: 0.5010 - val_accuracy: 0.9688 - val_loss: 0.1731 - learning_rate: 5.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8243 - loss: 0.4796 - val_accuracy: 0.9743 - val_loss: 0.1599 - learning_rate: 5.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8154 - loss: 0.4944 - val_accuracy: 0.9779 - val_loss: 0.1544 - learning_rate: 5.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8158 - loss: 0.4755 - val_accuracy: 0.9724 - val_loss: 0.1539 - learning_rate: 5.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.4704 - val_accuracy: 0.9743 - val_loss: 0.1587 - learning_rate: 5.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.4723 - val_accuracy: 0.9706 - val_loss: 0.1622 - learning_rate: 5.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.4919 - val_accuracy: 0.9724 - val_loss: 0.1518 - learning_rate: 5.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8210 - loss: 0.4725 - val_accuracy: 0.9724 - val_loss: 0.1518 - learning_rate: 5.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8388 - loss: 0.4378 - val_accuracy: 0.9743 - val_loss: 0.1494 - learning_rate: 5.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8302 - loss: 0.4712 - val_accuracy: 0.9743 - val_loss: 0.1489 - learning_rate: 5.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.4714 - val_accuracy: 0.9779 - val_loss: 0.1381 - learning_rate: 5.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8506 - loss: 0.4271 - val_accuracy: 0.9743 - val_loss: 0.1480 - learning_rate: 5.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8480 - loss: 0.4264 - val_accuracy: 0.9688 - val_loss: 0.1499 - learning_rate: 5.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8456 - loss: 0.4513 - val_accuracy: 0.9779 - val_loss: 0.1372 - learning_rate: 5.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.4447 - val_accuracy: 0.9816 - val_loss: 0.1349 - learning_rate: 5.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.4293 - val_accuracy: 0.9724 - val_loss: 0.1373 - learning_rate: 5.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.4214 - val_accuracy: 0.9779 - val_loss: 0.1331 - learning_rate: 5.0000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.4243 - val_accuracy: 0.9743 - val_loss: 0.1420 - learning_rate: 5.0000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8668 - loss: 0.3917 - val_accuracy: 0.9724 - val_loss: 0.1309 - learning_rate: 5.0000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.4184 - val_accuracy: 0.9779 - val_loss: 0.1281 - learning_rate: 5.0000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 0.4193 - val_accuracy: 0.9743 - val_loss: 0.1269 - learning_rate: 5.0000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 0.4128 - val_accuracy: 0.9724 - val_loss: 0.1416 - learning_rate: 5.0000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.4165 - val_accuracy: 0.9743 - val_loss: 0.1302 - learning_rate: 5.0000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8741 - loss: 0.3680 - val_accuracy: 0.9761 - val_loss: 0.1266 - learning_rate: 5.0000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8606 - loss: 0.3756 - val_accuracy: 0.9761 - val_loss: 0.1182 - learning_rate: 5.0000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8588 - loss: 0.4067 - val_accuracy: 0.9816 - val_loss: 0.1183 - learning_rate: 5.0000e-04\n",
            "Epoch 79/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.3747 - val_accuracy: 0.9890 - val_loss: 0.1133 - learning_rate: 5.0000e-04\n",
            "Epoch 80/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.3921 - val_accuracy: 0.9945 - val_loss: 0.1147 - learning_rate: 5.0000e-04\n",
            "Epoch 81/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.4027 - val_accuracy: 0.9835 - val_loss: 0.1181 - learning_rate: 5.0000e-04\n",
            "Epoch 82/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8870 - loss: 0.3549 - val_accuracy: 0.9908 - val_loss: 0.1089 - learning_rate: 5.0000e-04\n",
            "Epoch 83/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.3743 - val_accuracy: 0.9798 - val_loss: 0.1045 - learning_rate: 5.0000e-04\n",
            "Epoch 84/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8706 - loss: 0.3594 - val_accuracy: 0.9743 - val_loss: 0.1083 - learning_rate: 5.0000e-04\n",
            "Epoch 85/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8843 - loss: 0.3698 - val_accuracy: 0.9835 - val_loss: 0.1121 - learning_rate: 5.0000e-04\n",
            "Epoch 86/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8721 - loss: 0.3793 - val_accuracy: 0.9853 - val_loss: 0.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 87/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8929 - loss: 0.3579 - val_accuracy: 0.9835 - val_loss: 0.0997 - learning_rate: 5.0000e-04\n",
            "Epoch 88/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.3988 - val_accuracy: 0.9853 - val_loss: 0.0996 - learning_rate: 5.0000e-04\n",
            "Epoch 89/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 0.3858 - val_accuracy: 0.9945 - val_loss: 0.0946 - learning_rate: 5.0000e-04\n",
            "Epoch 90/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.3654 - val_accuracy: 0.9926 - val_loss: 0.0992 - learning_rate: 5.0000e-04\n",
            "Epoch 91/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.3348 - val_accuracy: 0.9816 - val_loss: 0.0982 - learning_rate: 5.0000e-04\n",
            "Epoch 92/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8735 - loss: 0.3393 - val_accuracy: 0.9798 - val_loss: 0.0984 - learning_rate: 5.0000e-04\n",
            "Epoch 93/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8793 - loss: 0.3464 - val_accuracy: 0.9890 - val_loss: 0.0908 - learning_rate: 5.0000e-04\n",
            "Epoch 94/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8728 - loss: 0.3530 - val_accuracy: 0.9908 - val_loss: 0.0951 - learning_rate: 5.0000e-04\n",
            "Epoch 95/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8756 - loss: 0.3448 - val_accuracy: 0.9853 - val_loss: 0.1001 - learning_rate: 5.0000e-04\n",
            "Epoch 96/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.3279 - val_accuracy: 0.9871 - val_loss: 0.0932 - learning_rate: 5.0000e-04\n",
            "Epoch 97/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8846 - loss: 0.3353 - val_accuracy: 0.9835 - val_loss: 0.0896 - learning_rate: 5.0000e-04\n",
            "Epoch 98/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.3409 - val_accuracy: 0.9853 - val_loss: 0.0956 - learning_rate: 5.0000e-04\n",
            "Epoch 99/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8975 - loss: 0.3069 - val_accuracy: 0.9853 - val_loss: 0.0873 - learning_rate: 5.0000e-04\n",
            "Epoch 100/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8902 - loss: 0.3405 - val_accuracy: 0.9945 - val_loss: 0.0855 - learning_rate: 5.0000e-04\n",
            "Epoch 101/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8703 - loss: 0.3654 - val_accuracy: 0.9853 - val_loss: 0.0918 - learning_rate: 5.0000e-04\n",
            "Epoch 102/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.3347 - val_accuracy: 0.9908 - val_loss: 0.0864 - learning_rate: 5.0000e-04\n",
            "Epoch 103/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.3120 - val_accuracy: 0.9871 - val_loss: 0.0824 - learning_rate: 5.0000e-04\n",
            "Epoch 104/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9026 - loss: 0.3066 - val_accuracy: 0.9890 - val_loss: 0.0788 - learning_rate: 5.0000e-04\n",
            "Epoch 105/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.3144 - val_accuracy: 0.9890 - val_loss: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 106/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.2960 - val_accuracy: 0.9890 - val_loss: 0.0794 - learning_rate: 5.0000e-04\n",
            "Epoch 107/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8992 - loss: 0.3110 - val_accuracy: 0.9908 - val_loss: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 108/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9124 - loss: 0.2669 - val_accuracy: 0.9853 - val_loss: 0.0815 - learning_rate: 5.0000e-04\n",
            "Epoch 109/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.3297 - val_accuracy: 0.9853 - val_loss: 0.0798 - learning_rate: 5.0000e-04\n",
            "Epoch 110/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.3034 - val_accuracy: 0.9908 - val_loss: 0.0766 - learning_rate: 5.0000e-04\n",
            "Epoch 111/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8983 - loss: 0.3324 - val_accuracy: 0.9963 - val_loss: 0.0740 - learning_rate: 5.0000e-04\n",
            "Epoch 112/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.2716 - val_accuracy: 0.9908 - val_loss: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 113/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2749 - val_accuracy: 0.9853 - val_loss: 0.0780 - learning_rate: 5.0000e-04\n",
            "Epoch 114/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8975 - loss: 0.3077 - val_accuracy: 0.9890 - val_loss: 0.0668 - learning_rate: 5.0000e-04\n",
            "Epoch 115/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.2909 - val_accuracy: 0.9908 - val_loss: 0.0702 - learning_rate: 5.0000e-04\n",
            "Epoch 116/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8957 - loss: 0.2955 - val_accuracy: 0.9908 - val_loss: 0.0730 - learning_rate: 5.0000e-04\n",
            "Epoch 117/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2816 - val_accuracy: 0.9890 - val_loss: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 118/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.2682 - val_accuracy: 0.9908 - val_loss: 0.0698 - learning_rate: 5.0000e-04\n",
            "Epoch 119/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8995 - loss: 0.3145 - val_accuracy: 0.9890 - val_loss: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 120/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9012 - loss: 0.2891 - val_accuracy: 0.9963 - val_loss: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 121/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9074 - loss: 0.2846 - val_accuracy: 0.9908 - val_loss: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 122/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9035 - loss: 0.2872 - val_accuracy: 0.9926 - val_loss: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 123/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9198 - loss: 0.2501 - val_accuracy: 0.9926 - val_loss: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 124/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8990 - loss: 0.3101 - val_accuracy: 0.9945 - val_loss: 0.0622 - learning_rate: 5.0000e-04\n",
            "Epoch 125/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.2602 - val_accuracy: 0.9926 - val_loss: 0.0562 - learning_rate: 5.0000e-04\n",
            "Epoch 126/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.2837 - val_accuracy: 0.9926 - val_loss: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 127/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2585 - val_accuracy: 0.9945 - val_loss: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 128/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2596 - val_accuracy: 0.9835 - val_loss: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 129/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.2869 - val_accuracy: 0.9871 - val_loss: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 130/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.2371 - val_accuracy: 0.9835 - val_loss: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 131/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2283 - val_accuracy: 0.9963 - val_loss: 0.0580 - learning_rate: 5.0000e-04\n",
            "Epoch 132/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9316 - loss: 0.2393 - val_accuracy: 0.9982 - val_loss: 0.0585 - learning_rate: 1.5000e-04\n",
            "Epoch 133/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.2238 - val_accuracy: 0.9963 - val_loss: 0.0612 - learning_rate: 1.5000e-04\n",
            "Epoch 134/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9222 - loss: 0.2336 - val_accuracy: 0.9982 - val_loss: 0.0556 - learning_rate: 1.5000e-04\n",
            "Epoch 135/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2541 - val_accuracy: 0.9963 - val_loss: 0.0594 - learning_rate: 1.5000e-04\n",
            "Epoch 136/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.2384 - val_accuracy: 0.9982 - val_loss: 0.0593 - learning_rate: 1.5000e-04\n",
            "Epoch 137/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9089 - loss: 0.2347 - val_accuracy: 0.9982 - val_loss: 0.0606 - learning_rate: 1.5000e-04\n",
            "Epoch 138/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.2556 - val_accuracy: 0.9982 - val_loss: 0.0580 - learning_rate: 1.5000e-04\n",
            "Epoch 139/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.2332 - val_accuracy: 0.9982 - val_loss: 0.0571 - learning_rate: 1.5000e-04\n",
            "Epoch 140/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2336 - val_accuracy: 0.9982 - val_loss: 0.0559 - learning_rate: 1.5000e-04\n",
            "Epoch 141/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.2204 - val_accuracy: 0.9982 - val_loss: 0.0558 - learning_rate: 4.5000e-05\n",
            "Epoch 142/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2454 - val_accuracy: 0.9982 - val_loss: 0.0552 - learning_rate: 4.5000e-05\n",
            "Epoch 143/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2269 - val_accuracy: 0.9982 - val_loss: 0.0561 - learning_rate: 4.5000e-05\n",
            "Epoch 144/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2369 - val_accuracy: 0.9982 - val_loss: 0.0562 - learning_rate: 4.5000e-05\n",
            "Epoch 145/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.2694 - val_accuracy: 0.9982 - val_loss: 0.0567 - learning_rate: 4.5000e-05\n",
            "Epoch 146/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9249 - loss: 0.2294 - val_accuracy: 0.9982 - val_loss: 0.0577 - learning_rate: 4.5000e-05\n",
            "Epoch 147/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9200 - loss: 0.2500 - val_accuracy: 0.9982 - val_loss: 0.0558 - learning_rate: 4.5000e-05\n",
            "Epoch 148/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2329 - val_accuracy: 0.9982 - val_loss: 0.0568 - learning_rate: 4.5000e-05\n",
            "Epoch 149/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.2203 - val_accuracy: 0.9982 - val_loss: 0.0564 - learning_rate: 1.3500e-05\n",
            "Epoch 150/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9295 - loss: 0.2223 - val_accuracy: 0.9982 - val_loss: 0.0565 - learning_rate: 1.3500e-05\n",
            "Epoch 151/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9294 - loss: 0.2156 - val_accuracy: 0.9982 - val_loss: 0.0560 - learning_rate: 1.3500e-05\n",
            "Epoch 152/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.2396 - val_accuracy: 0.9982 - val_loss: 0.0560 - learning_rate: 1.3500e-05\n",
            "Epoch 153/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.2208 - val_accuracy: 0.9982 - val_loss: 0.0561 - learning_rate: 1.3500e-05\n",
            "Epoch 154/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.2090 - val_accuracy: 0.9982 - val_loss: 0.0556 - learning_rate: 1.3500e-05\n",
            "\n",
            "Model Information:\n",
            "  Structure: 56â†’28â†’1, Parameters: 6,441, Size: 25.2KB\n",
            "  Training epochs: 154\n",
            "\n",
            "Test Results:\n",
            "  Accuracy: 0.818, AUC: 0.890\n",
            "\n",
            "Normal Class (Label=1):\n",
            "  Precision: 0.897\n",
            "  Recall: 0.844\n",
            "  F1: 0.869\n",
            "\n",
            "Anomaly Class (Label=0):\n",
            "  Precision: 0.651\n",
            "  Recall: 0.750\n",
            "  F1: 0.697\n",
            "\n",
            "Summary:\n",
            "  Structure: 56â†’28â†’1\n",
            "  Parameters: 6,441\n",
            "  Size: 25.2KB\n",
            "  Overall F1: 0.783\n",
            "  Normal Class F1: 0.869\n",
            "  Anomaly Class F1: 0.697\n",
            "\n",
            "====== Starting Run 4/5 ======\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "========================================\n",
            "Training set: 1600 samples, Test set: 400 samples\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "Training set: (1600, 85), Anomaly rate: 28.0%\n",
            "Test set: (400, 85), Anomaly rate: 28.0%\n",
            "Data augmentation: 1600 -> 2720 samples\n",
            "Starting training...\n",
            "Epoch 1/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5191 - loss: 1.5538 - val_accuracy: 0.8879 - val_loss: 0.3552 - learning_rate: 5.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5185 - loss: 1.1307 - val_accuracy: 0.9099 - val_loss: 0.3330 - learning_rate: 5.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5396 - loss: 1.0013 - val_accuracy: 0.9099 - val_loss: 0.3321 - learning_rate: 5.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5652 - loss: 0.9930 - val_accuracy: 0.9283 - val_loss: 0.3279 - learning_rate: 5.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.9333 - val_accuracy: 0.9246 - val_loss: 0.3313 - learning_rate: 5.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.8640 - val_accuracy: 0.9375 - val_loss: 0.3229 - learning_rate: 5.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 0.9073 - val_accuracy: 0.9449 - val_loss: 0.3202 - learning_rate: 5.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 0.8716 - val_accuracy: 0.9449 - val_loss: 0.3160 - learning_rate: 5.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6163 - loss: 0.8601 - val_accuracy: 0.9522 - val_loss: 0.3204 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6306 - loss: 0.8383 - val_accuracy: 0.9504 - val_loss: 0.3168 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6490 - loss: 0.8109 - val_accuracy: 0.9559 - val_loss: 0.2996 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6646 - loss: 0.7874 - val_accuracy: 0.9522 - val_loss: 0.3025 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6781 - loss: 0.7846 - val_accuracy: 0.9540 - val_loss: 0.2965 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6616 - loss: 0.7902 - val_accuracy: 0.9559 - val_loss: 0.2968 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6745 - loss: 0.7628 - val_accuracy: 0.9522 - val_loss: 0.2828 - learning_rate: 5.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6770 - loss: 0.7527 - val_accuracy: 0.9522 - val_loss: 0.2909 - learning_rate: 5.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6983 - loss: 0.7391 - val_accuracy: 0.9596 - val_loss: 0.2714 - learning_rate: 5.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6785 - loss: 0.7542 - val_accuracy: 0.9614 - val_loss: 0.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 0.7168 - val_accuracy: 0.9522 - val_loss: 0.2713 - learning_rate: 5.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7123 - loss: 0.6943 - val_accuracy: 0.9467 - val_loss: 0.2620 - learning_rate: 5.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6967 - loss: 0.7200 - val_accuracy: 0.9577 - val_loss: 0.2583 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.6933 - val_accuracy: 0.9614 - val_loss: 0.2482 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7177 - loss: 0.6996 - val_accuracy: 0.9632 - val_loss: 0.2482 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7298 - loss: 0.6659 - val_accuracy: 0.9669 - val_loss: 0.2429 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.6968 - val_accuracy: 0.9651 - val_loss: 0.2423 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7325 - loss: 0.6620 - val_accuracy: 0.9669 - val_loss: 0.2290 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7297 - loss: 0.6873 - val_accuracy: 0.9688 - val_loss: 0.2225 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 0.6800 - val_accuracy: 0.9706 - val_loss: 0.2285 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7391 - loss: 0.6440 - val_accuracy: 0.9761 - val_loss: 0.2232 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7619 - loss: 0.6323 - val_accuracy: 0.9761 - val_loss: 0.2178 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7488 - loss: 0.6279 - val_accuracy: 0.9706 - val_loss: 0.2127 - learning_rate: 5.0000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7501 - loss: 0.6346 - val_accuracy: 0.9743 - val_loss: 0.2133 - learning_rate: 5.0000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7748 - loss: 0.6010 - val_accuracy: 0.9816 - val_loss: 0.2048 - learning_rate: 5.0000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 0.6382 - val_accuracy: 0.9890 - val_loss: 0.2003 - learning_rate: 5.0000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7801 - loss: 0.6058 - val_accuracy: 0.9835 - val_loss: 0.1975 - learning_rate: 5.0000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7717 - loss: 0.6027 - val_accuracy: 0.9853 - val_loss: 0.1996 - learning_rate: 5.0000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7846 - loss: 0.6053 - val_accuracy: 0.9816 - val_loss: 0.1890 - learning_rate: 5.0000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7763 - loss: 0.5856 - val_accuracy: 0.9798 - val_loss: 0.1894 - learning_rate: 5.0000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7939 - loss: 0.5565 - val_accuracy: 0.9816 - val_loss: 0.1792 - learning_rate: 5.0000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7767 - loss: 0.5744 - val_accuracy: 0.9853 - val_loss: 0.1789 - learning_rate: 5.0000e-04\n",
            "Epoch 41/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7814 - loss: 0.5685 - val_accuracy: 0.9835 - val_loss: 0.1785 - learning_rate: 5.0000e-04\n",
            "Epoch 42/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7838 - loss: 0.5817 - val_accuracy: 0.9890 - val_loss: 0.1780 - learning_rate: 5.0000e-04\n",
            "Epoch 43/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.5635 - val_accuracy: 0.9853 - val_loss: 0.1753 - learning_rate: 5.0000e-04\n",
            "Epoch 44/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.5347 - val_accuracy: 0.9853 - val_loss: 0.1714 - learning_rate: 5.0000e-04\n",
            "Epoch 45/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7888 - loss: 0.5463 - val_accuracy: 0.9835 - val_loss: 0.1735 - learning_rate: 5.0000e-04\n",
            "Epoch 46/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.5594 - val_accuracy: 0.9871 - val_loss: 0.1696 - learning_rate: 5.0000e-04\n",
            "Epoch 47/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7947 - loss: 0.5497 - val_accuracy: 0.9835 - val_loss: 0.1625 - learning_rate: 5.0000e-04\n",
            "Epoch 48/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7765 - loss: 0.5573 - val_accuracy: 0.9853 - val_loss: 0.1540 - learning_rate: 5.0000e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.5042 - val_accuracy: 0.9853 - val_loss: 0.1585 - learning_rate: 5.0000e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8059 - loss: 0.5227 - val_accuracy: 0.9853 - val_loss: 0.1593 - learning_rate: 5.0000e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.5501 - val_accuracy: 0.9871 - val_loss: 0.1549 - learning_rate: 5.0000e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8004 - loss: 0.5244 - val_accuracy: 0.9853 - val_loss: 0.1619 - learning_rate: 5.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.5051 - val_accuracy: 0.9871 - val_loss: 0.1453 - learning_rate: 5.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.5053 - val_accuracy: 0.9853 - val_loss: 0.1491 - learning_rate: 5.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 0.4951 - val_accuracy: 0.9871 - val_loss: 0.1390 - learning_rate: 5.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8253 - loss: 0.4778 - val_accuracy: 0.9890 - val_loss: 0.1397 - learning_rate: 5.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8084 - loss: 0.5145 - val_accuracy: 0.9871 - val_loss: 0.1362 - learning_rate: 5.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.4611 - val_accuracy: 0.9890 - val_loss: 0.1357 - learning_rate: 5.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.4790 - val_accuracy: 0.9926 - val_loss: 0.1391 - learning_rate: 5.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.5006 - val_accuracy: 0.9890 - val_loss: 0.1355 - learning_rate: 5.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8238 - loss: 0.4752 - val_accuracy: 0.9871 - val_loss: 0.1351 - learning_rate: 5.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.4705 - val_accuracy: 0.9853 - val_loss: 0.1241 - learning_rate: 5.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.4704 - val_accuracy: 0.9908 - val_loss: 0.1375 - learning_rate: 5.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8356 - loss: 0.4690 - val_accuracy: 0.9926 - val_loss: 0.1258 - learning_rate: 5.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.4719 - val_accuracy: 0.9890 - val_loss: 0.1272 - learning_rate: 5.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.4448 - val_accuracy: 0.9908 - val_loss: 0.1259 - learning_rate: 5.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8359 - loss: 0.4822 - val_accuracy: 0.9945 - val_loss: 0.1259 - learning_rate: 5.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 0.4624 - val_accuracy: 0.9945 - val_loss: 0.1255 - learning_rate: 5.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.4607 - val_accuracy: 0.9963 - val_loss: 0.1183 - learning_rate: 1.5000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8435 - loss: 0.4398 - val_accuracy: 0.9963 - val_loss: 0.1207 - learning_rate: 1.5000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.4385 - val_accuracy: 0.9963 - val_loss: 0.1185 - learning_rate: 1.5000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8411 - loss: 0.4353 - val_accuracy: 0.9963 - val_loss: 0.1215 - learning_rate: 1.5000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.4446 - val_accuracy: 0.9963 - val_loss: 0.1193 - learning_rate: 1.5000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8408 - loss: 0.4301 - val_accuracy: 0.9963 - val_loss: 0.1232 - learning_rate: 1.5000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8548 - loss: 0.4220 - val_accuracy: 0.9963 - val_loss: 0.1167 - learning_rate: 1.5000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8627 - loss: 0.4001 - val_accuracy: 0.9963 - val_loss: 0.1160 - learning_rate: 1.5000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8444 - loss: 0.4249 - val_accuracy: 0.9963 - val_loss: 0.1130 - learning_rate: 1.5000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8497 - loss: 0.4230 - val_accuracy: 0.9963 - val_loss: 0.1131 - learning_rate: 1.5000e-04\n",
            "Epoch 79/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8575 - loss: 0.4215 - val_accuracy: 0.9963 - val_loss: 0.1151 - learning_rate: 1.5000e-04\n",
            "Epoch 80/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8435 - loss: 0.4362 - val_accuracy: 0.9945 - val_loss: 0.1177 - learning_rate: 1.5000e-04\n",
            "Epoch 81/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8501 - loss: 0.4259 - val_accuracy: 0.9963 - val_loss: 0.1158 - learning_rate: 1.5000e-04\n",
            "Epoch 82/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8471 - loss: 0.4360 - val_accuracy: 0.9963 - val_loss: 0.1133 - learning_rate: 1.5000e-04\n",
            "Epoch 83/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.4273 - val_accuracy: 0.9963 - val_loss: 0.1099 - learning_rate: 1.5000e-04\n",
            "Epoch 84/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.4070 - val_accuracy: 0.9945 - val_loss: 0.1133 - learning_rate: 1.5000e-04\n",
            "Epoch 85/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8423 - loss: 0.4217 - val_accuracy: 0.9963 - val_loss: 0.1107 - learning_rate: 1.5000e-04\n",
            "Epoch 86/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.3963 - val_accuracy: 0.9963 - val_loss: 0.1129 - learning_rate: 1.5000e-04\n",
            "Epoch 87/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8623 - loss: 0.4025 - val_accuracy: 0.9963 - val_loss: 0.1069 - learning_rate: 1.5000e-04\n",
            "Epoch 88/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8540 - loss: 0.4216 - val_accuracy: 0.9963 - val_loss: 0.1049 - learning_rate: 1.5000e-04\n",
            "Epoch 89/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8683 - loss: 0.3895 - val_accuracy: 0.9963 - val_loss: 0.1073 - learning_rate: 1.5000e-04\n",
            "Epoch 90/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8681 - loss: 0.3918 - val_accuracy: 0.9963 - val_loss: 0.1053 - learning_rate: 1.5000e-04\n",
            "Epoch 91/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.4196 - val_accuracy: 0.9963 - val_loss: 0.1054 - learning_rate: 1.5000e-04\n",
            "Epoch 92/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8457 - loss: 0.4447 - val_accuracy: 0.9963 - val_loss: 0.1093 - learning_rate: 1.5000e-04\n",
            "Epoch 93/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.4220 - val_accuracy: 0.9963 - val_loss: 0.1060 - learning_rate: 1.5000e-04\n",
            "Epoch 94/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8701 - loss: 0.3890 - val_accuracy: 0.9963 - val_loss: 0.1082 - learning_rate: 1.5000e-04\n",
            "Epoch 95/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.3899 - val_accuracy: 0.9963 - val_loss: 0.1067 - learning_rate: 4.5000e-05\n",
            "Epoch 96/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8703 - loss: 0.3681 - val_accuracy: 0.9963 - val_loss: 0.1063 - learning_rate: 4.5000e-05\n",
            "Epoch 97/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 0.3947 - val_accuracy: 0.9963 - val_loss: 0.1074 - learning_rate: 4.5000e-05\n",
            "Epoch 98/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8712 - loss: 0.3785 - val_accuracy: 0.9963 - val_loss: 0.1064 - learning_rate: 4.5000e-05\n",
            "Epoch 99/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8655 - loss: 0.3984 - val_accuracy: 0.9963 - val_loss: 0.1057 - learning_rate: 4.5000e-05\n",
            "Epoch 100/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8662 - loss: 0.3961 - val_accuracy: 0.9963 - val_loss: 0.1035 - learning_rate: 4.5000e-05\n",
            "Epoch 101/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8682 - loss: 0.3777 - val_accuracy: 0.9963 - val_loss: 0.1041 - learning_rate: 4.5000e-05\n",
            "Epoch 102/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.4095 - val_accuracy: 0.9963 - val_loss: 0.1034 - learning_rate: 4.5000e-05\n",
            "Epoch 103/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.3961 - val_accuracy: 0.9963 - val_loss: 0.1052 - learning_rate: 4.5000e-05\n",
            "Epoch 104/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.3990 - val_accuracy: 0.9963 - val_loss: 0.1060 - learning_rate: 4.5000e-05\n",
            "Epoch 105/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.3845 - val_accuracy: 0.9963 - val_loss: 0.1043 - learning_rate: 4.5000e-05\n",
            "Epoch 106/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.4136 - val_accuracy: 0.9963 - val_loss: 0.1034 - learning_rate: 4.5000e-05\n",
            "Epoch 107/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8662 - loss: 0.3940 - val_accuracy: 0.9963 - val_loss: 0.1035 - learning_rate: 1.3500e-05\n",
            "Epoch 108/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8726 - loss: 0.3716 - val_accuracy: 0.9963 - val_loss: 0.1033 - learning_rate: 1.3500e-05\n",
            "Epoch 109/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.4260 - val_accuracy: 0.9963 - val_loss: 0.1033 - learning_rate: 1.3500e-05\n",
            "Epoch 110/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.4141 - val_accuracy: 0.9963 - val_loss: 0.1037 - learning_rate: 1.3500e-05\n",
            "Epoch 111/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8532 - loss: 0.4177 - val_accuracy: 0.9963 - val_loss: 0.1036 - learning_rate: 1.3500e-05\n",
            "Epoch 112/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3958 - val_accuracy: 0.9963 - val_loss: 0.1032 - learning_rate: 1.3500e-05\n",
            "Epoch 113/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8700 - loss: 0.3639 - val_accuracy: 0.9963 - val_loss: 0.1030 - learning_rate: 1.3500e-05\n",
            "Epoch 114/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8670 - loss: 0.4010 - val_accuracy: 0.9963 - val_loss: 0.1030 - learning_rate: 1.3500e-05\n",
            "Epoch 115/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.4079 - val_accuracy: 0.9963 - val_loss: 0.1030 - learning_rate: 1.3500e-05\n",
            "Epoch 116/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.3903 - val_accuracy: 0.9963 - val_loss: 0.1028 - learning_rate: 1.3500e-05\n",
            "Epoch 117/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8555 - loss: 0.3884 - val_accuracy: 0.9963 - val_loss: 0.1029 - learning_rate: 1.3500e-05\n",
            "Epoch 118/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8765 - loss: 0.3723 - val_accuracy: 0.9963 - val_loss: 0.1030 - learning_rate: 1.3500e-05\n",
            "Epoch 119/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8726 - loss: 0.3734 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 1.3500e-05\n",
            "Epoch 120/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8612 - loss: 0.3847 - val_accuracy: 0.9963 - val_loss: 0.1024 - learning_rate: 1.3500e-05\n",
            "Epoch 121/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8770 - loss: 0.3757 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 1.3500e-05\n",
            "Epoch 122/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8564 - loss: 0.3878 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 1.3500e-05\n",
            "Epoch 123/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8693 - loss: 0.4034 - val_accuracy: 0.9963 - val_loss: 0.1022 - learning_rate: 1.3500e-05\n",
            "Epoch 124/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8589 - loss: 0.4010 - val_accuracy: 0.9963 - val_loss: 0.1024 - learning_rate: 1.3500e-05\n",
            "Epoch 125/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8660 - loss: 0.3767 - val_accuracy: 0.9963 - val_loss: 0.1027 - learning_rate: 1.3500e-05\n",
            "Epoch 126/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.4015 - val_accuracy: 0.9963 - val_loss: 0.1026 - learning_rate: 1.3500e-05\n",
            "Epoch 127/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8622 - loss: 0.3867 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 1.3500e-05\n",
            "Epoch 128/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.3856 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 1.3500e-05\n",
            "Epoch 129/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8705 - loss: 0.3767 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 1.3500e-05\n",
            "Epoch 130/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8644 - loss: 0.3810 - val_accuracy: 0.9963 - val_loss: 0.1026 - learning_rate: 4.0500e-06\n",
            "Epoch 131/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8652 - loss: 0.3922 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 4.0500e-06\n",
            "Epoch 132/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.3946 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 4.0500e-06\n",
            "Epoch 133/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8634 - loss: 0.4003 - val_accuracy: 0.9963 - val_loss: 0.1025 - learning_rate: 4.0500e-06\n",
            "Epoch 134/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8657 - loss: 0.3992 - val_accuracy: 0.9963 - val_loss: 0.1024 - learning_rate: 4.0500e-06\n",
            "Epoch 135/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.3814 - val_accuracy: 0.9963 - val_loss: 0.1024 - learning_rate: 4.0500e-06\n",
            "\n",
            "Model Information:\n",
            "  Structure: 56â†’28â†’1, Parameters: 6,441, Size: 25.2KB\n",
            "  Training epochs: 135\n",
            "\n",
            "Test Results:\n",
            "  Accuracy: 0.782, AUC: 0.889\n",
            "\n",
            "Normal Class (Label=1):\n",
            "  Precision: 0.939\n",
            "  Recall: 0.747\n",
            "  F1: 0.832\n",
            "\n",
            "Anomaly Class (Label=0):\n",
            "  Precision: 0.573\n",
            "  Recall: 0.875\n",
            "  F1: 0.693\n",
            "\n",
            "Summary:\n",
            "  Structure: 56â†’28â†’1\n",
            "  Parameters: 6,441\n",
            "  Size: 25.2KB\n",
            "  Overall F1: 0.762\n",
            "  Normal Class F1: 0.832\n",
            "  Anomaly Class F1: 0.693\n",
            "\n",
            "====== Starting Run 5/5 ======\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "========================================\n",
            "Training set: 1600 samples, Test set: 400 samples\n",
            "Optimized Lightweight Model Training (56â†’28â†’1)\n",
            "Training set: (1600, 85), Anomaly rate: 28.0%\n",
            "Test set: (400, 85), Anomaly rate: 28.0%\n",
            "Data augmentation: 1600 -> 2720 samples\n",
            "Starting training...\n",
            "Epoch 1/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5442 - loss: 1.4141 - val_accuracy: 0.8915 - val_loss: 0.4150 - learning_rate: 5.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5517 - loss: 1.0312 - val_accuracy: 0.9154 - val_loss: 0.3794 - learning_rate: 5.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5531 - loss: 0.9952 - val_accuracy: 0.9173 - val_loss: 0.3748 - learning_rate: 5.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6032 - loss: 0.8975 - val_accuracy: 0.9228 - val_loss: 0.3601 - learning_rate: 5.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6112 - loss: 0.9116 - val_accuracy: 0.9210 - val_loss: 0.3744 - learning_rate: 5.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6220 - loss: 0.8792 - val_accuracy: 0.9246 - val_loss: 0.3562 - learning_rate: 5.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6230 - loss: 0.8723 - val_accuracy: 0.9283 - val_loss: 0.3480 - learning_rate: 5.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6477 - loss: 0.8329 - val_accuracy: 0.9228 - val_loss: 0.3383 - learning_rate: 5.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6468 - loss: 0.8238 - val_accuracy: 0.9320 - val_loss: 0.3303 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6569 - loss: 0.8096 - val_accuracy: 0.9320 - val_loss: 0.3148 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6658 - loss: 0.7980 - val_accuracy: 0.9301 - val_loss: 0.3088 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6726 - loss: 0.7738 - val_accuracy: 0.9265 - val_loss: 0.3036 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6948 - loss: 0.7672 - val_accuracy: 0.9210 - val_loss: 0.3055 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7079 - loss: 0.7345 - val_accuracy: 0.9246 - val_loss: 0.2947 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7012 - loss: 0.7336 - val_accuracy: 0.9246 - val_loss: 0.2898 - learning_rate: 5.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7135 - loss: 0.7412 - val_accuracy: 0.9246 - val_loss: 0.2860 - learning_rate: 5.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7089 - loss: 0.7323 - val_accuracy: 0.9320 - val_loss: 0.2829 - learning_rate: 5.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7177 - loss: 0.7194 - val_accuracy: 0.9265 - val_loss: 0.2752 - learning_rate: 5.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7307 - loss: 0.7008 - val_accuracy: 0.9338 - val_loss: 0.2672 - learning_rate: 5.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7256 - loss: 0.6970 - val_accuracy: 0.9375 - val_loss: 0.2615 - learning_rate: 5.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 0.6910 - val_accuracy: 0.9412 - val_loss: 0.2489 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7419 - loss: 0.6698 - val_accuracy: 0.9412 - val_loss: 0.2520 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7435 - loss: 0.6509 - val_accuracy: 0.9430 - val_loss: 0.2494 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7341 - loss: 0.6654 - val_accuracy: 0.9375 - val_loss: 0.2428 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7377 - loss: 0.6600 - val_accuracy: 0.9393 - val_loss: 0.2403 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7430 - loss: 0.6532 - val_accuracy: 0.9449 - val_loss: 0.2382 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7447 - loss: 0.6433 - val_accuracy: 0.9522 - val_loss: 0.2391 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6245 - val_accuracy: 0.9559 - val_loss: 0.2296 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7741 - loss: 0.5930 - val_accuracy: 0.9596 - val_loss: 0.2145 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7533 - loss: 0.6313 - val_accuracy: 0.9559 - val_loss: 0.2161 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7743 - loss: 0.6087 - val_accuracy: 0.9614 - val_loss: 0.2140 - learning_rate: 5.0000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7803 - loss: 0.6096 - val_accuracy: 0.9632 - val_loss: 0.2115 - learning_rate: 5.0000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7658 - loss: 0.5823 - val_accuracy: 0.9614 - val_loss: 0.2030 - learning_rate: 5.0000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7734 - loss: 0.5720 - val_accuracy: 0.9596 - val_loss: 0.2015 - learning_rate: 5.0000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7811 - loss: 0.5843 - val_accuracy: 0.9669 - val_loss: 0.1936 - learning_rate: 5.0000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7891 - loss: 0.5820 - val_accuracy: 0.9688 - val_loss: 0.1912 - learning_rate: 5.0000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.5534 - val_accuracy: 0.9761 - val_loss: 0.1784 - learning_rate: 5.0000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.5819 - val_accuracy: 0.9688 - val_loss: 0.1926 - learning_rate: 5.0000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.5556 - val_accuracy: 0.9706 - val_loss: 0.1890 - learning_rate: 5.0000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7894 - loss: 0.5531 - val_accuracy: 0.9669 - val_loss: 0.1912 - learning_rate: 5.0000e-04\n",
            "Epoch 41/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.5430 - val_accuracy: 0.9688 - val_loss: 0.1805 - learning_rate: 5.0000e-04\n",
            "Epoch 42/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.5445 - val_accuracy: 0.9706 - val_loss: 0.1832 - learning_rate: 5.0000e-04\n",
            "Epoch 43/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8041 - loss: 0.5178 - val_accuracy: 0.9706 - val_loss: 0.1722 - learning_rate: 5.0000e-04\n",
            "Epoch 44/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7949 - loss: 0.5289 - val_accuracy: 0.9706 - val_loss: 0.1784 - learning_rate: 5.0000e-04\n",
            "Epoch 45/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.5224 - val_accuracy: 0.9816 - val_loss: 0.1729 - learning_rate: 5.0000e-04\n",
            "Epoch 46/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8240 - loss: 0.4979 - val_accuracy: 0.9798 - val_loss: 0.1660 - learning_rate: 5.0000e-04\n",
            "Epoch 47/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8083 - loss: 0.5283 - val_accuracy: 0.9816 - val_loss: 0.1632 - learning_rate: 5.0000e-04\n",
            "Epoch 48/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7992 - loss: 0.5243 - val_accuracy: 0.9779 - val_loss: 0.1678 - learning_rate: 5.0000e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8159 - loss: 0.5047 - val_accuracy: 0.9743 - val_loss: 0.1635 - learning_rate: 5.0000e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.5140 - val_accuracy: 0.9798 - val_loss: 0.1572 - learning_rate: 5.0000e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8165 - loss: 0.5077 - val_accuracy: 0.9871 - val_loss: 0.1523 - learning_rate: 5.0000e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8117 - loss: 0.4820 - val_accuracy: 0.9853 - val_loss: 0.1518 - learning_rate: 5.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 0.4732 - val_accuracy: 0.9871 - val_loss: 0.1571 - learning_rate: 5.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8308 - loss: 0.4730 - val_accuracy: 0.9835 - val_loss: 0.1559 - learning_rate: 5.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8263 - loss: 0.4802 - val_accuracy: 0.9816 - val_loss: 0.1502 - learning_rate: 5.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.4317 - val_accuracy: 0.9835 - val_loss: 0.1463 - learning_rate: 5.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8319 - loss: 0.4723 - val_accuracy: 0.9835 - val_loss: 0.1317 - learning_rate: 5.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8379 - loss: 0.4518 - val_accuracy: 0.9816 - val_loss: 0.1368 - learning_rate: 5.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8350 - loss: 0.4680 - val_accuracy: 0.9835 - val_loss: 0.1425 - learning_rate: 5.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8286 - loss: 0.4599 - val_accuracy: 0.9835 - val_loss: 0.1311 - learning_rate: 5.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8331 - loss: 0.4528 - val_accuracy: 0.9835 - val_loss: 0.1308 - learning_rate: 5.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8431 - loss: 0.4586 - val_accuracy: 0.9871 - val_loss: 0.1216 - learning_rate: 5.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8397 - loss: 0.4225 - val_accuracy: 0.9871 - val_loss: 0.1236 - learning_rate: 5.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8404 - loss: 0.4429 - val_accuracy: 0.9835 - val_loss: 0.1222 - learning_rate: 5.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8535 - loss: 0.4363 - val_accuracy: 0.9853 - val_loss: 0.1225 - learning_rate: 5.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8325 - loss: 0.4742 - val_accuracy: 0.9890 - val_loss: 0.1193 - learning_rate: 5.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8444 - loss: 0.4339 - val_accuracy: 0.9871 - val_loss: 0.1211 - learning_rate: 5.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8572 - loss: 0.4119 - val_accuracy: 0.9853 - val_loss: 0.1180 - learning_rate: 5.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8571 - loss: 0.4159 - val_accuracy: 0.9871 - val_loss: 0.1127 - learning_rate: 5.0000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8499 - loss: 0.4259 - val_accuracy: 0.9890 - val_loss: 0.1123 - learning_rate: 5.0000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8567 - loss: 0.4192 - val_accuracy: 0.9871 - val_loss: 0.1137 - learning_rate: 5.0000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3962 - val_accuracy: 0.9908 - val_loss: 0.1132 - learning_rate: 5.0000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8511 - loss: 0.4172 - val_accuracy: 0.9908 - val_loss: 0.1114 - learning_rate: 5.0000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.4243 - val_accuracy: 0.9835 - val_loss: 0.1146 - learning_rate: 5.0000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8676 - loss: 0.3865 - val_accuracy: 0.9908 - val_loss: 0.1001 - learning_rate: 5.0000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8610 - loss: 0.3899 - val_accuracy: 0.9853 - val_loss: 0.1029 - learning_rate: 5.0000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8502 - loss: 0.4256 - val_accuracy: 0.9835 - val_loss: 0.1083 - learning_rate: 5.0000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8794 - loss: 0.3751 - val_accuracy: 0.9853 - val_loss: 0.0962 - learning_rate: 5.0000e-04\n",
            "Epoch 79/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8603 - loss: 0.4243 - val_accuracy: 0.9871 - val_loss: 0.0998 - learning_rate: 5.0000e-04\n",
            "Epoch 80/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8686 - loss: 0.3770 - val_accuracy: 0.9890 - val_loss: 0.0968 - learning_rate: 5.0000e-04\n",
            "Epoch 81/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8717 - loss: 0.3824 - val_accuracy: 0.9908 - val_loss: 0.0950 - learning_rate: 5.0000e-04\n",
            "Epoch 82/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 0.3774 - val_accuracy: 0.9871 - val_loss: 0.0943 - learning_rate: 5.0000e-04\n",
            "Epoch 83/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.3694 - val_accuracy: 0.9890 - val_loss: 0.0905 - learning_rate: 5.0000e-04\n",
            "Epoch 84/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.3542 - val_accuracy: 0.9816 - val_loss: 0.0911 - learning_rate: 5.0000e-04\n",
            "Epoch 85/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8719 - loss: 0.3594 - val_accuracy: 0.9908 - val_loss: 0.0870 - learning_rate: 5.0000e-04\n",
            "Epoch 86/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8851 - loss: 0.3360 - val_accuracy: 0.9908 - val_loss: 0.0895 - learning_rate: 5.0000e-04\n",
            "Epoch 87/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8774 - loss: 0.3337 - val_accuracy: 0.9908 - val_loss: 0.0850 - learning_rate: 5.0000e-04\n",
            "Epoch 88/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.3602 - val_accuracy: 0.9908 - val_loss: 0.0834 - learning_rate: 5.0000e-04\n",
            "Epoch 89/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8838 - loss: 0.3509 - val_accuracy: 0.9908 - val_loss: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 90/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.3225 - val_accuracy: 0.9871 - val_loss: 0.0887 - learning_rate: 5.0000e-04\n",
            "Epoch 91/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.3520 - val_accuracy: 0.9890 - val_loss: 0.0818 - learning_rate: 5.0000e-04\n",
            "Epoch 92/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8954 - loss: 0.3427 - val_accuracy: 0.9890 - val_loss: 0.0783 - learning_rate: 5.0000e-04\n",
            "Epoch 93/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.3383 - val_accuracy: 0.9871 - val_loss: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 94/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.3171 - val_accuracy: 0.9926 - val_loss: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 95/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8907 - loss: 0.3393 - val_accuracy: 0.9890 - val_loss: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 96/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8837 - loss: 0.3374 - val_accuracy: 0.9871 - val_loss: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 97/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8788 - loss: 0.3313 - val_accuracy: 0.9890 - val_loss: 0.0707 - learning_rate: 5.0000e-04\n",
            "Epoch 98/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8990 - loss: 0.3294 - val_accuracy: 0.9945 - val_loss: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 99/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8884 - loss: 0.3199 - val_accuracy: 0.9908 - val_loss: 0.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 100/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9018 - loss: 0.2917 - val_accuracy: 0.9908 - val_loss: 0.0729 - learning_rate: 5.0000e-04\n",
            "Epoch 101/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8916 - loss: 0.3216 - val_accuracy: 0.9926 - val_loss: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 102/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9017 - loss: 0.3090 - val_accuracy: 0.9926 - val_loss: 0.0610 - learning_rate: 5.0000e-04\n",
            "Epoch 103/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.3139 - val_accuracy: 0.9963 - val_loss: 0.0600 - learning_rate: 5.0000e-04\n",
            "Epoch 104/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.3121 - val_accuracy: 0.9963 - val_loss: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 105/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8942 - loss: 0.2999 - val_accuracy: 0.9945 - val_loss: 0.0658 - learning_rate: 5.0000e-04\n",
            "Epoch 106/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8943 - loss: 0.2955 - val_accuracy: 0.9945 - val_loss: 0.0597 - learning_rate: 5.0000e-04\n",
            "Epoch 107/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.2817 - val_accuracy: 0.9926 - val_loss: 0.0652 - learning_rate: 5.0000e-04\n",
            "Epoch 108/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.3249 - val_accuracy: 0.9926 - val_loss: 0.0605 - learning_rate: 5.0000e-04\n",
            "Epoch 109/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8835 - loss: 0.3217 - val_accuracy: 0.9945 - val_loss: 0.0661 - learning_rate: 5.0000e-04\n",
            "Epoch 110/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9071 - loss: 0.2852 - val_accuracy: 0.9926 - val_loss: 0.0554 - learning_rate: 5.0000e-04\n",
            "Epoch 111/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.2847 - val_accuracy: 0.9926 - val_loss: 0.0646 - learning_rate: 5.0000e-04\n",
            "Epoch 112/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9037 - loss: 0.3061 - val_accuracy: 0.9908 - val_loss: 0.0683 - learning_rate: 5.0000e-04\n",
            "Epoch 113/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.2775 - val_accuracy: 0.9963 - val_loss: 0.0540 - learning_rate: 5.0000e-04\n",
            "Epoch 114/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.2708 - val_accuracy: 0.9963 - val_loss: 0.0597 - learning_rate: 5.0000e-04\n",
            "Epoch 115/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2575 - val_accuracy: 0.9963 - val_loss: 0.0548 - learning_rate: 5.0000e-04\n",
            "Epoch 116/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9044 - loss: 0.2756 - val_accuracy: 0.9945 - val_loss: 0.0590 - learning_rate: 5.0000e-04\n",
            "Epoch 117/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9119 - loss: 0.2602 - val_accuracy: 0.9945 - val_loss: 0.0580 - learning_rate: 5.0000e-04\n",
            "Epoch 118/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.2730 - val_accuracy: 0.9871 - val_loss: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 119/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9002 - loss: 0.2920 - val_accuracy: 0.9945 - val_loss: 0.0551 - learning_rate: 5.0000e-04\n",
            "Epoch 120/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9066 - loss: 0.2896 - val_accuracy: 0.9945 - val_loss: 0.0548 - learning_rate: 1.5000e-04\n",
            "Epoch 121/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9053 - loss: 0.2659 - val_accuracy: 0.9963 - val_loss: 0.0576 - learning_rate: 1.5000e-04\n",
            "Epoch 122/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9118 - loss: 0.2698 - val_accuracy: 0.9963 - val_loss: 0.0569 - learning_rate: 1.5000e-04\n",
            "Epoch 123/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9046 - loss: 0.2648 - val_accuracy: 0.9963 - val_loss: 0.0580 - learning_rate: 1.5000e-04\n",
            "Epoch 124/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9166 - loss: 0.2560 - val_accuracy: 0.9963 - val_loss: 0.0556 - learning_rate: 1.5000e-04\n",
            "Epoch 125/300\n",
            "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.2857 - val_accuracy: 0.9963 - val_loss: 0.0545 - learning_rate: 1.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Information:\n",
            "  Structure: 56â†’28â†’1, Parameters: 6,441, Size: 25.2KB\n",
            "  Training epochs: 125\n",
            "\n",
            "Test Results:\n",
            "  Accuracy: 0.830, AUC: 0.898\n",
            "\n",
            "Normal Class (Label=1):\n",
            "  Precision: 0.933\n",
            "  Recall: 0.823\n",
            "  F1: 0.875\n",
            "\n",
            "Anomaly Class (Label=0):\n",
            "  Precision: 0.651\n",
            "  Recall: 0.848\n",
            "  F1: 0.736\n",
            "\n",
            "Summary:\n",
            "  Structure: 56â†’28â†’1\n",
            "  Parameters: 6,441\n",
            "  Size: 25.2KB\n",
            "  Overall F1: 0.805\n",
            "  Normal Class F1: 0.875\n",
            "  Anomaly Class F1: 0.736\n",
            "\n",
            "New best model saved (Average F1: 0.805)\n",
            "\n",
            "====== Best Run Summary ======\n",
            "Best Overall F1: 0.805\n",
            "Normal F1: 0.875\n",
            "Anomaly F1: 0.736\n",
            "\n",
            "Generating and saving training history plot to 'figure_5_4_training_curves.png'...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def run_multiple_trainings(features_df, n_runs=5, test_size=0.2, epochs=300):\n",
        "    best_result = None\n",
        "    best_f1 = -1.0\n",
        "\n",
        "    for i in range(n_runs):\n",
        "        print(f\"\\n====== Starting Run {i+1}/{n_runs} ======\")\n",
        "        result = run_lightweight_training(features_df, test_size=test_size, epochs=epochs)\n",
        "\n",
        "        # Use the average F1 score (normal + anomaly) as the comparison metric\n",
        "        avg_f1 = (result['normal_metrics']['f1'] + result['anomaly_metrics']['f1']) / 2\n",
        "\n",
        "        if avg_f1 > best_f1:\n",
        "            best_f1 = avg_f1\n",
        "            best_result = result\n",
        "\n",
        "            # Save the best model and scaler\n",
        "            result['model'].save('best_model.h5')\n",
        "            result['model'].save('best_model.keras')  # Replaces the older version\n",
        "            joblib.dump(result['scaler'], 'scaler.pkl')\n",
        "            print(f\"\\nNew best model saved (Average F1: {avg_f1:.3f})\")\n",
        "\n",
        "    print(\"\\n====== Best Run Summary ======\")\n",
        "    print(f\"Best Overall F1: {best_f1:.3f}\")\n",
        "    print(f\"Normal F1: {best_result['normal_metrics']['f1']:.3f}\")\n",
        "    print(f\"Anomaly F1: {best_result['anomaly_metrics']['f1']:.3f}\")\n",
        "\n",
        "    if best_result and 'history' in best_result:\n",
        "        plot_training_history(best_result['history'])\n",
        "\n",
        "\n",
        "    return best_result\n",
        "\n",
        "\n",
        "best_model_result = run_multiple_trainings(features_df, n_runs=5, test_size=0.2, epochs=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd9vK1gSZyBa",
        "outputId": "9a94d562-1fd4-452c-ab86-b12d58701e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest K-Fold Validation (k=5)\n",
            "Samples: 2000, Features: 85, Normal/Anomaly: 1440/560\n",
            "Fold 1: Acc=0.802, AUC=0.843 | Normal P/R/F1=0.803/0.962/0.875 | Anomaly P/R/F1=0.800/0.393/0.527\n",
            "Fold 2: Acc=0.807, AUC=0.881 | Normal P/R/F1=0.801/0.976/0.879 | Anomaly P/R/F1=0.857/0.375/0.522\n",
            "Fold 3: Acc=0.790, AUC=0.872 | Normal P/R/F1=0.787/0.972/0.870 | Anomaly P/R/F1=0.818/0.321/0.462\n",
            "Fold 4: Acc=0.823, AUC=0.897 | Normal P/R/F1=0.816/0.972/0.887 | Anomaly P/R/F1=0.860/0.438/0.580\n",
            "Fold 5: Acc=0.782, AUC=0.857 | Normal P/R/F1=0.777/0.979/0.866 | Anomaly P/R/F1=0.838/0.277/0.416\n",
            "\n",
            "============================================================\n",
            "Final Results (Mean Â± Std Dev):\n",
            "============================================================\n",
            "Overall Metrics:\n",
            "  ACCURACY: 0.801 Â± 0.014\n",
            "  AUC     : 0.870 Â± 0.018\n",
            "\n",
            "Normal Class (Label=1):\n",
            "  PRECISION: 0.797 Â± 0.014\n",
            "  RECALL  : 0.972 Â± 0.006\n",
            "  F1      : 0.876 Â± 0.007\n",
            "\n",
            "Anomaly Class (Label=0):\n",
            "  PRECISION: 0.835 Â± 0.023\n",
            "  RECALL  : 0.361 Â± 0.056\n",
            "  F1      : 0.501 Â± 0.057\n",
            "\n",
            "Top 15 Important Features:\n",
            "----------------------------------------\n",
            " 1. rms_mean                 : 0.0292\n",
            " 2. mel_max                  : 0.0273\n",
            " 3. rms_std                  : 0.0192\n",
            " 4. mfcc_2_std               : 0.0185\n",
            " 5. spectral_bandwidth_std   : 0.0179\n",
            " 6. contrast_6_mean          : 0.0173\n",
            " 7. contrast_4_mean          : 0.0169\n",
            " 8. mfcc_11_std              : 0.0164\n",
            " 9. mfcc_0_mean              : 0.0164\n",
            "10. contrast_2_mean          : 0.0160\n",
            "11. mfcc_3_mean              : 0.0153\n",
            "12. mel_mean                 : 0.0152\n",
            "13. mfcc_0_skew              : 0.0150\n",
            "14. mfcc_5_mean              : 0.0150\n",
            "15. zcr_mean                 : 0.0148\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, confusion_matrix)\n",
        "import numpy as np\n",
        "\n",
        "def random_forest_kfold_detailed(features_df, k=5):\n",
        "    \"\"\"Random Forest K-Fold Cross-Validation with Detailed Metrics\"\"\"\n",
        "    print(f\"Random Forest K-Fold Validation (k={k})\")\n",
        "\n",
        "    # Prepare data\n",
        "    feature_cols = [col for col in features_df.columns\n",
        "                    if col not in ['filename', 'category', 'is_normal', 'fold']]\n",
        "    X = features_df[feature_cols].values\n",
        "    y = features_df['is_normal'].values\n",
        "\n",
        "    print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}, Normal/Anomaly: {np.sum(y==1)}/{np.sum(y==0)}\")\n",
        "\n",
        "    # K-Fold split\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store metrics\n",
        "    overall_metrics = {'accuracy': [], 'auc': []}\n",
        "    normal_metrics = {'precision': [], 'recall': [], 'f1': []}\n",
        "    anomaly_metrics = {'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
        "        # Split data\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # Normalize\n",
        "        scaler = RobustScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_val = scaler.transform(X_val)\n",
        "        X_train = np.nan_to_num(X_train)\n",
        "        X_val = np.nan_to_num(X_val)\n",
        "\n",
        "        # Train model\n",
        "        rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "        rf.fit(X_train, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = rf.predict(X_val)\n",
        "        y_proba = rf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        # Compute metrics\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "        # Metrics for normal class (label=1)\n",
        "        normal_prec = precision_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
        "        normal_rec = recall_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
        "        normal_f1 = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "        # Metrics for anomaly class (label=0)\n",
        "        anomaly_prec = precision_score(y_val, y_pred, pos_label=0, zero_division=0)\n",
        "        anomaly_rec = recall_score(y_val, y_pred, pos_label=0, zero_division=0)\n",
        "        anomaly_f1 = f1_score(y_val, y_pred, pos_label=0, zero_division=0)\n",
        "\n",
        "        # Store results\n",
        "        overall_metrics['accuracy'].append(acc)\n",
        "        overall_metrics['auc'].append(auc)\n",
        "        normal_metrics['precision'].append(normal_prec)\n",
        "        normal_metrics['recall'].append(normal_rec)\n",
        "        normal_metrics['f1'].append(normal_f1)\n",
        "        anomaly_metrics['precision'].append(anomaly_prec)\n",
        "        anomaly_metrics['recall'].append(anomaly_rec)\n",
        "        anomaly_metrics['f1'].append(anomaly_f1)\n",
        "\n",
        "        print(f\"Fold {fold}: Acc={acc:.3f}, AUC={auc:.3f} | \"\n",
        "              f\"Normal P/R/F1={normal_prec:.3f}/{normal_rec:.3f}/{normal_f1:.3f} | \"\n",
        "              f\"Anomaly P/R/F1={anomaly_prec:.3f}/{anomaly_rec:.3f}/{anomaly_f1:.3f}\")\n",
        "\n",
        "    # Final result summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Final Results (Mean Â± Std Dev):\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(\"Overall Metrics:\")\n",
        "    for metric, values in overall_metrics.items():\n",
        "        mean_val = np.mean(values)\n",
        "        std_val = np.std(values)\n",
        "        print(f\"  {metric.upper():<8}: {mean_val:.3f} Â± {std_val:.3f}\")\n",
        "\n",
        "    print(\"\\nNormal Class (Label=1):\")\n",
        "    for metric, values in normal_metrics.items():\n",
        "        mean_val = np.mean(values)\n",
        "        std_val = np.std(values)\n",
        "        print(f\"  {metric.upper():<8}: {mean_val:.3f} Â± {std_val:.3f}\")\n",
        "\n",
        "    print(\"\\nAnomaly Class (Label=0):\")\n",
        "    for metric, values in anomaly_metrics.items():\n",
        "        mean_val = np.mean(values)\n",
        "        std_val = np.std(values)\n",
        "        print(f\"  {metric.upper():<8}: {mean_val:.3f} Â± {std_val:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'overall': overall_metrics,\n",
        "        'normal': normal_metrics,\n",
        "        'anomaly': anomaly_metrics\n",
        "    }\n",
        "\n",
        "def get_feature_importance(features_df, top_n=10):\n",
        "    \"\"\"Get top-N feature importances using Random Forest\"\"\"\n",
        "    feature_cols = [col for col in features_df.columns\n",
        "                    if col not in ['filename', 'category', 'is_normal', 'fold']]\n",
        "    X = features_df[feature_cols].values\n",
        "    y = features_df['is_normal'].values\n",
        "\n",
        "    # Data preprocessing\n",
        "    scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_scaled = np.nan_to_num(X_scaled)\n",
        "\n",
        "    # Train model\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_scaled, y)\n",
        "\n",
        "    # Get importance\n",
        "    importance = rf.feature_importances_\n",
        "    indices = np.argsort(importance)[::-1]\n",
        "\n",
        "    print(f\"\\nTop {top_n} Important Features:\")\n",
        "    print(\"-\" * 40)\n",
        "    for i in range(min(top_n, len(feature_cols))):\n",
        "        idx = indices[i]\n",
        "        print(f\"{i+1:2d}. {feature_cols[idx]:<25}: {importance[idx]:.4f}\")\n",
        "\n",
        "    return list(zip([feature_cols[i] for i in indices], importance[indices]))\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Run detailed evaluation\n",
        "    results = random_forest_kfold_detailed(features_df, k=5)\n",
        "\n",
        "    # Get feature importance\n",
        "    feature_importance = get_feature_importance(features_df, top_n=15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import scipy.stats\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Load the full Keras model\n",
        "try:\n",
        "    keras_model = tf.keras.models.load_model(\"model/best_model.keras\")\n",
        "    print(\"Keras model ('best_model.keras') loaded successfully.\")\n",
        "except Exception as e:\n",
        "    keras_model = None\n",
        "    print(f\"Failed to load Keras model: {e}\")\n",
        "\n",
        "# Load the TensorFlow Lite model and initialize the interpreter\n",
        "try:\n",
        "    interpreter = tf.lite.Interpreter(model_path=\"model/best_model.tflite\")\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    print(\"TFLite model ('model/best_model.tflite') loaded successfully.\")\n",
        "except Exception as e:\n",
        "    interpreter = None\n",
        "    print(f\"Failed to load TFLite model: {e}\")\n",
        "\n",
        "# Load the data scaler\n",
        "try:\n",
        "    scaler = joblib.load(\"scaler.pkl\")\n",
        "    print(\"Scaler ('scaler.pkl') loaded successfully.\")\n",
        "except Exception as e:\n",
        "    scaler = None\n",
        "    print(f\"Failed to load Scaler: {e}\")\n",
        "\n",
        "# --- 2. Data Preparation ---\n",
        "# (This section is the same as your original scripts)\n",
        "SMART_HOME_CRITICAL_ANOMALIES = [\n",
        "    'crackling_fire', 'crying_baby', 'sneezing', 'coughing', 'door_knock', 'glass_breaking',\n",
        "    'helicopter', 'chainsaw', 'siren', 'car_horn', 'engine', 'train', 'airplane', 'hand_saw'\n",
        "]\n",
        "ALL_ESC50_CATEGORIES = [\n",
        "    'dog', 'rooster', 'pig', 'cow', 'frog', 'cat', 'hen', 'insects', 'sheep', 'crow', 'rain',\n",
        "    'sea_waves', 'crackling_fire', 'crickets', 'chirping_birds', 'water_drops', 'wind',\n",
        "    'pouring_water', 'toilet_flush', 'thunderstorm', 'crying_baby', 'sneezing', 'clapping',\n",
        "    'breathing', 'coughing', 'footsteps', 'laughing', 'brushing_teeth', 'snoring',\n",
        "    'drinking_sipping', 'door_knock', 'mouse_click', 'keyboard_typing', 'door_wood_creaks',\n",
        "    'can_opening', 'washing_machine', 'vacuum_cleaner', 'clock_alarm', 'clock_tick',\n",
        "    'glass_breaking', 'helicopter', 'chainsaw', 'siren', 'car_horn', 'engine', 'train',\n",
        "    'church_bells', 'airplane', 'fireworks', 'hand_saw'\n",
        "]\n",
        "NORMAL_CATEGORIES = [cat for cat in ALL_ESC50_CATEGORIES if cat not in SMART_HOME_CRITICAL_ANOMALIES]\n",
        "\n",
        "meta_path = \"ESC-50-master/meta/esc50.csv\"\n",
        "meta_df = pd.read_csv(meta_path)\n",
        "meta_df['is_normal'] = meta_df['category'].isin(NORMAL_CATEGORIES).astype(int)\n",
        "sample_df = meta_df.sample(n=500, random_state=42).reset_index(drop=True)\n",
        "audio_path = Path(\"ESC-50-master/audio\")\n",
        "print(f\"Data preparation complete. {len(sample_df)} samples selected for validation.\")\n",
        "\n",
        "# --- 3. Feature Extraction Function ---\n",
        "def extract_comprehensive_features_fast(signal, sr):\n",
        "    features = {}\n",
        "    hop_length=512; n_fft=1024\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, hop_length=hop_length, n_fft=n_fft)\n",
        "    mfcc_stats = np.array([np.mean(mfcc, axis=1), np.std(mfcc, axis=1), scipy.stats.skew(mfcc, axis=1), scipy.stats.kurtosis(mfcc, axis=1)])\n",
        "    for i in range(13):\n",
        "        features[f'mfcc_{i}_mean']=mfcc_stats[0,i]; features[f'mfcc_{i}_std']=mfcc_stats[1,i]; features[f'mfcc_{i}_skew']=mfcc_stats[2,i]; features[f'mfcc_{i}_kurt']=mfcc_stats[3,i]\n",
        "    stft=librosa.stft(signal, hop_length=hop_length, n_fft=n_fft); magnitude=np.abs(stft)\n",
        "    features['spectral_centroid_mean']=np.mean(librosa.feature.spectral_centroid(S=magnitude, sr=sr)[0]); features['spectral_centroid_std']=np.std(librosa.feature.spectral_centroid(S=magnitude, sr=sr)[0])\n",
        "    features['spectral_bandwidth_mean']=np.mean(librosa.feature.spectral_bandwidth(S=magnitude, sr=sr)[0]); features['spectral_bandwidth_std']=np.std(librosa.feature.spectral_bandwidth(S=magnitude, sr=sr)[0])\n",
        "    features['spectral_rolloff_mean']=np.mean(librosa.feature.spectral_rolloff(S=magnitude, sr=sr)[0]); features['spectral_rolloff_std']=np.std(librosa.feature.spectral_rolloff(S=magnitude, sr=sr)[0])\n",
        "    zcr=librosa.feature.zero_crossing_rate(signal, hop_length=hop_length)[0]; features['zcr_mean']=np.mean(zcr); features['zcr_std']=np.std(zcr)\n",
        "    rms=librosa.feature.rms(y=signal, hop_length=hop_length)[0]; features['rms_mean']=np.mean(rms); features['rms_std']=np.std(rms)\n",
        "    contrast=librosa.feature.spectral_contrast(S=magnitude, sr=sr, n_bands=6)\n",
        "    for i in range(contrast.shape[0]): features[f'contrast_{i}_mean']=np.mean(contrast[i])\n",
        "    chroma=librosa.feature.chroma_stft(S=magnitude, sr=sr)\n",
        "    for i in range(12): features[f'chroma_{i}_mean']=np.mean(chroma[i])\n",
        "    mel_spec=librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=32, hop_length=hop_length, n_fft=n_fft); mel_spec_db=librosa.power_to_db(mel_spec)\n",
        "    features['mel_mean']=np.mean(mel_spec_db); features['mel_std']=np.std(mel_spec_db); features['mel_max']=np.max(mel_spec_db); features['mel_min']=np.min(mel_spec_db)\n",
        "    for key, value in features.items():\n",
        "        if np.isnan(value) or np.isinf(value): features[key]=0.0\n",
        "    return features\n",
        "\n",
        "# --- 4. Unified Inference Loop for Both Models ---\n",
        "results = []\n",
        "print(\"\\nStarting inference on the same samples for both models...\")\n",
        "if keras_model and interpreter and scaler:\n",
        "    for _, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
        "        filepath = audio_path / row['filename']\n",
        "        try:\n",
        "            # Common processing steps\n",
        "            signal, sr = librosa.load(filepath, sr=16000, duration=5.0)\n",
        "            features = extract_comprehensive_features_fast(signal, sr)\n",
        "            X = pd.DataFrame([features])\n",
        "            X_scaled = scaler.transform(X)\n",
        "            X_scaled = np.nan_to_num(X_scaled)\n",
        "\n",
        "            # Keras model inference\n",
        "            keras_prob = keras_model.predict(X_scaled, verbose=0)[0][0]\n",
        "            keras_pred = int(keras_prob > 0.5)\n",
        "\n",
        "            # TFLite model inference\n",
        "            interpreter.set_tensor(input_details[0]['index'], X_scaled.astype(np.float32))\n",
        "            interpreter.invoke()\n",
        "            tflite_prob = interpreter.get_tensor(output_details[0]['index'])[0][0]\n",
        "            tflite_pred = int(tflite_prob > 0.5)\n",
        "\n",
        "            results.append({\n",
        "                'filename': row['filename'],\n",
        "                'category': row['category'],\n",
        "                'true_label': row['is_normal'],\n",
        "                'keras_prob': keras_prob,\n",
        "                'keras_pred': keras_pred,\n",
        "                'tflite_prob': tflite_prob,\n",
        "                'tflite_pred': tflite_pred\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Skipped {row['filename']} due to error: {e}\")\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # --- 5. Side-by-Side Comparative Results Display ---\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"Keras vs. TFLite Model Performance Comparison\")\n",
        "    print(f\"(Metrics calculated for the 'Normal' class, pos_label=1, on {len(results_df)} samples)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    y_true = results_df['true_label'].values\n",
        "    y_pred_keras = results_df['keras_pred'].values\n",
        "    y_pred_tflite = results_df['tflite_pred'].values\n",
        "\n",
        "    # Calculate metrics for Keras model\n",
        "    acc_keras = accuracy_score(y_true, y_pred_keras)\n",
        "    prec_keras = precision_score(y_true, y_pred_keras, pos_label=1, zero_division=0)\n",
        "    rec_keras = recall_score(y_true, y_pred_keras, pos_label=1, zero_division=0)\n",
        "    f1_keras = f1_score(y_true, y_pred_keras, pos_label=1, zero_division=0)\n",
        "\n",
        "    # Calculate metrics for TFLite model\n",
        "    acc_tflite = accuracy_score(y_true, y_pred_tflite)\n",
        "    prec_tflite = precision_score(y_true, y_pred_tflite, pos_label=1, zero_division=0)\n",
        "    rec_tflite = recall_score(y_true, y_pred_tflite, pos_label=1, zero_division=0)\n",
        "    f1_tflite = f1_score(y_true, y_pred_tflite, pos_label=1, zero_division=0)\n",
        "\n",
        "    # Print comparison table\n",
        "    print(f\"{'Metric':<22} | {'Keras Model (.keras)':<25} | {'TFLite Model (.tflite)':<25}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"{'Accuracy':<22} | {acc_keras:<25.3f} | {acc_tflite:<25.3f}\")\n",
        "    print(f\"{'Precision (Normal)':<22} | {prec_keras:<25.3f} | {prec_tflite:<25.3f}\")\n",
        "    print(f\"{'Recall (Normal)':<22} | {rec_keras:<25.3f} | {rec_tflite:<25.3f}\")\n",
        "    print(f\"{'F1-Score (Normal)':<22} | {f1_keras:<25.3f} | {f1_tflite:<25.3f}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Calculate and print prediction consistency\n",
        "    consistency = np.mean(results_df['keras_pred'] == results_df['tflite_pred'])\n",
        "    print(f\"\\nPrediction Consistency: {consistency:.1%}\")\n",
        "    print(\"(The percentage of samples where both models gave the same prediction)\")\n",
        "\n",
        "    # Print confusion matrices\n",
        "    cm_keras = confusion_matrix(y_true, y_pred_keras)\n",
        "    cm_tflite = confusion_matrix(y_true, y_pred_tflite)\n",
        "    print(\"\\nKeras Confusion Matrix (rows=true, cols=predicted):\\n\", cm_keras)\n",
        "    print(\"\\nTFLite Confusion Matrix (rows=true, cols=predicted):\\n\", cm_tflite)\n",
        "else:\n",
        "    print(\"\\nCould not run comparison due to errors in loading models or scaler.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWR-OqMlklLi",
        "outputId": "a9690f4a-8a4a-49c5-e118-a059f6dddf05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras model ('best_model.keras') loaded successfully.\n",
            "TFLite model ('model/best_model.tflite') loaded successfully.\n",
            "Scaler ('scaler.pkl') loaded successfully.\n",
            "Data preparation complete. 500 samples selected for validation.\n",
            "\n",
            "Starting inference on the same samples for both models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [04:15<00:00,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "Keras vs. TFLite Model Performance Comparison\n",
            "(Metrics calculated for the 'Normal' class, pos_label=1, on 500 samples)\n",
            "================================================================================\n",
            "Metric                 | Keras Model (.keras)      | TFLite Model (.tflite)   \n",
            "--------------------------------------------------------------------------------\n",
            "Accuracy               | 0.974                     | 0.974                    \n",
            "Precision (Normal)     | 0.989                     | 0.989                    \n",
            "Recall (Normal)        | 0.976                     | 0.976                    \n",
            "F1-Score (Normal)      | 0.982                     | 0.982                    \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Prediction Consistency: 100.0%\n",
            "(The percentage of samples where both models gave the same prediction)\n",
            "\n",
            "Keras Confusion Matrix (rows=true, cols=predicted):\n",
            " [[123   4]\n",
            " [  9 364]]\n",
            "\n",
            "TFLite Confusion Matrix (rows=true, cols=predicted):\n",
            " [[123   4]\n",
            " [  9 364]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}